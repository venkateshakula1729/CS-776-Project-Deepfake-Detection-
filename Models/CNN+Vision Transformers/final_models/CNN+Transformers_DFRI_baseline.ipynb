{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":3134515,"sourceType":"datasetVersion","datasetId":1909705}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# import kagglehub\n\n# # Download latest version\n# path = kagglehub.dataset_download(\"manjilkarki/deepfake-and-real-images\")\n\n# print(\"Path to dataset files:\", path)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-15T09:48:32.821833Z","iopub.execute_input":"2025-04-15T09:48:32.822278Z","iopub.status.idle":"2025-04-15T09:48:38.031279Z","shell.execute_reply.started":"2025-04-15T09:48:32.822244Z","shell.execute_reply":"2025-04-15T09:48:38.030261Z"}},"outputs":[{"name":"stdout","text":"Path to dataset files: /kaggle/input/deepfake-and-real-images\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets, transforms\nfrom sklearn.metrics import classification_report\nfrom tqdm import tqdm\nimport kagglehub","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T09:50:37.251521Z","iopub.execute_input":"2025-04-15T09:50:37.251840Z","iopub.status.idle":"2025-04-15T09:50:44.525177Z","shell.execute_reply.started":"2025-04-15T09:50:37.251815Z","shell.execute_reply":"2025-04-15T09:50:44.524614Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# ---- Device Setup ----\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nNUM_CLASSES = 2\nBATCH_SIZE = 32\nEPOCHS = 5","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T09:50:44.526234Z","iopub.execute_input":"2025-04-15T09:50:44.526624Z","iopub.status.idle":"2025-04-15T09:50:44.593631Z","shell.execute_reply.started":"2025-04-15T09:50:44.526598Z","shell.execute_reply":"2025-04-15T09:50:44.592767Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# ---- Transforms ----\ntransform = transforms.Compose([\n    transforms.Resize((64, 64)),\n    transforms.ToTensor()\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T09:51:08.699434Z","iopub.execute_input":"2025-04-15T09:51:08.700195Z","iopub.status.idle":"2025-04-15T09:51:08.703866Z","shell.execute_reply.started":"2025-04-15T09:51:08.700170Z","shell.execute_reply":"2025-04-15T09:51:08.703103Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# ---- Helper: Fix Class Labels ----\ndef remap_targets(dataset):\n    mapping = {\"Real\": 0, \"Fake\": 1}\n    dataset.samples = [(p, mapping[p.split(\"/\")[-2]]) for p, _ in dataset.samples]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T09:51:17.423282Z","iopub.execute_input":"2025-04-15T09:51:17.423811Z","iopub.status.idle":"2025-04-15T09:51:17.427849Z","shell.execute_reply.started":"2025-04-15T09:51:17.423786Z","shell.execute_reply":"2025-04-15T09:51:17.427265Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"train_dataset = datasets.ImageFolder(f\"/kaggle/input/deepfake-and-real-images/Dataset/Train\", transform=transform)\nremap_targets(train_dataset)\ntrain_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T09:52:05.433279Z","iopub.execute_input":"2025-04-15T09:52:05.433812Z","iopub.status.idle":"2025-04-15T09:54:53.725881Z","shell.execute_reply.started":"2025-04-15T09:52:05.433787Z","shell.execute_reply":"2025-04-15T09:54:53.725217Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"val_dataset = datasets.ImageFolder(f\"/kaggle/input/deepfake-and-real-images/Dataset/Validation\", transform=transform)\nremap_targets(val_dataset)\nval_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T09:55:07.327127Z","iopub.execute_input":"2025-04-15T09:55:07.327410Z","iopub.status.idle":"2025-04-15T09:55:54.319964Z","shell.execute_reply.started":"2025-04-15T09:55:07.327389Z","shell.execute_reply":"2025-04-15T09:55:54.319374Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"test_dataset = datasets.ImageFolder(f\"/kaggle/input/deepfake-and-real-images/Dataset/Test\", transform=transform)\nremap_targets(test_dataset)\ntest_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T09:55:54.321188Z","iopub.execute_input":"2025-04-15T09:55:54.321447Z","iopub.status.idle":"2025-04-15T09:56:08.322489Z","shell.execute_reply.started":"2025-04-15T09:55:54.321423Z","shell.execute_reply":"2025-04-15T09:56:08.321934Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# ---- Hybrid Model ----\nclass HybridModel(nn.Module):\n    def __init__(self):\n        super(HybridModel, self).__init__()\n        self.cnn = nn.Sequential(\n            nn.Conv2d(3, 64, 3, padding=1), nn.ReLU(),\n            nn.Conv2d(64, 128, 3, padding=1), nn.ReLU(),\n            nn.MaxPool2d(2),\n            nn.Conv2d(128, 256, 3, padding=1), nn.ReLU(),\n            nn.MaxPool2d(2)\n        )\n        self.patch_embed = nn.Conv2d(256, 128, kernel_size=4, stride=4)\n        self.transformer = nn.TransformerEncoder(\n            nn.TransformerEncoderLayer(d_model=128, nhead=4, dim_feedforward=256),\n            num_layers=2\n        )\n        self.classifier = nn.Linear(128, NUM_CLASSES)\n\n    def forward(self, x):\n        x = self.cnn(x)\n        x = self.patch_embed(x)         # [B, 128, 8, 8]\n        x = x.flatten(2).permute(2, 0, 1)  # [64, B, 128]\n        x = self.transformer(x)         # [64, B, 128]\n        x = x.mean(dim=0)               # [B, 128]\n        return self.classifier(x)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T09:56:08.323196Z","iopub.execute_input":"2025-04-15T09:56:08.323436Z","iopub.status.idle":"2025-04-15T09:56:08.329879Z","shell.execute_reply.started":"2025-04-15T09:56:08.323415Z","shell.execute_reply":"2025-04-15T09:56:08.329247Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# ---- Train & Eval Functions ----\ndef train(model, loader, optimizer, criterion):\n    model.train()\n    running_loss, correct = 0, 0\n    for x, y in tqdm(loader, desc=\"Training\"):\n        x, y = x.to(device), y.to(device)\n        optimizer.zero_grad()\n        out = model(x)\n        loss = criterion(out, y)\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item()\n        correct += (out.argmax(1) == y).sum().item()\n    acc = correct / len(loader.dataset)\n    return running_loss / len(loader), acc\n\ndef evaluate(model, loader, criterion):\n    model.eval()\n    loss, correct = 0, 0\n    with torch.no_grad():\n        for x, y in loader:\n            x, y = x.to(device), y.to(device)\n            out = model(x)\n            loss += criterion(out, y).item()\n            correct += (out.argmax(1) == y).sum().item()\n    acc = correct / len(loader.dataset)\n    return loss / len(loader), acc","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T09:56:08.331767Z","iopub.execute_input":"2025-04-15T09:56:08.331974Z","iopub.status.idle":"2025-04-15T09:56:08.351109Z","shell.execute_reply.started":"2025-04-15T09:56:08.331959Z","shell.execute_reply":"2025-04-15T09:56:08.350528Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"# ---- Training Loop ----\nmodel = HybridModel().to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\ncriterion = nn.CrossEntropyLoss()\n\nfor epoch in range(EPOCHS):\n    print(f\"\\nEpoch {epoch+1}/{EPOCHS}\")\n    train_loss, train_acc = train(model, train_loader, optimizer, criterion)\n    val_loss, val_acc = evaluate(model, val_loader, criterion)\n    print(f\"Train Acc: {train_acc:.4f} | Val Acc: {val_acc:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T09:56:08.351757Z","iopub.execute_input":"2025-04-15T09:56:08.351921Z","iopub.status.idle":"2025-04-15T10:56:30.507421Z","shell.execute_reply.started":"2025-04-15T09:56:08.351909Z","shell.execute_reply":"2025-04-15T10:56:30.506721Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1/5\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 4376/4376 [18:48<00:00,  3.88it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Acc: 0.8241 | Val Acc: 0.8794\n\nEpoch 2/5\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 4376/4376 [06:54<00:00, 10.57it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Acc: 0.9230 | Val Acc: 0.8711\n\nEpoch 3/5\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 4376/4376 [07:14<00:00, 10.07it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Acc: 0.9442 | Val Acc: 0.9258\n\nEpoch 4/5\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 4376/4376 [07:03<00:00, 10.32it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Acc: 0.9547 | Val Acc: 0.9295\n\nEpoch 5/5\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 4376/4376 [07:17<00:00,  9.99it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Acc: 0.9628 | Val Acc: 0.9209\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"# ---- Testing ----\nmodel.eval()\ny_true = []\ny_pred = []\n\nwith torch.no_grad():\n    for x, y in tqdm(test_loader, desc=\"Testing\"):\n        x = x.to(device)\n        out = model(x)\n        preds = out.argmax(1).cpu()\n        y_true.extend(y.numpy())\n        y_pred.extend(preds.numpy())\n\nprint(\"\\nTest Classification Report:\")\nprint(classification_report(y_true, y_pred, target_names=[\"REAL\", \"FAKE\"]))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T10:56:30.508475Z","iopub.execute_input":"2025-04-15T10:56:30.508784Z","iopub.status.idle":"2025-04-15T10:58:13.935448Z","shell.execute_reply.started":"2025-04-15T10:56:30.508756Z","shell.execute_reply":"2025-04-15T10:58:13.934679Z"}},"outputs":[{"name":"stderr","text":"Testing: 100%|██████████| 341/341 [01:43<00:00,  3.30it/s]","output_type":"stream"},{"name":"stdout","text":"\nTest Classification Report:\n              precision    recall  f1-score   support\n\n        REAL       0.86      0.95      0.90      5413\n        FAKE       0.94      0.85      0.89      5492\n\n    accuracy                           0.90     10905\n   macro avg       0.90      0.90      0.90     10905\nweighted avg       0.90      0.90      0.90     10905\n\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"# ---- Save Trained Model ----\ntorch.save(model.state_dict(), \"hybrid_deepfake_DFRI_dataset.pth\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T10:58:13.936332Z","iopub.execute_input":"2025-04-15T10:58:13.936587Z","iopub.status.idle":"2025-04-15T10:58:13.951595Z","shell.execute_reply.started":"2025-04-15T10:58:13.936564Z","shell.execute_reply":"2025-04-15T10:58:13.950896Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}