{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceType":"datasetVersion","sourceId":5256696,"datasetId":3041726,"databundleVersionId":5329502}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Hybrid CNN + Transformer for CIFAKE (Notebook Style)\n\nimport torch\nimport torch.nn as nn\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader, random_split\nimport torch.nn.functional as F\nfrom tqdm import tqdm  # <-- added for progress bar\nfrom sklearn.metrics import classification_report\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-13T13:34:05.155951Z","iopub.execute_input":"2025-04-13T13:34:05.156437Z","iopub.status.idle":"2025-04-13T13:34:05.160707Z","shell.execute_reply.started":"2025-04-13T13:34:05.156413Z","shell.execute_reply":"2025-04-13T13:34:05.159933Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"# ---- Setup ----\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nBATCH_SIZE = 64\nEPOCHS = 5\nIMG_SIZE = 128\nNUM_CLASSES = 2","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T13:34:18.598427Z","iopub.execute_input":"2025-04-13T13:34:18.599219Z","iopub.status.idle":"2025-04-13T13:34:18.602968Z","shell.execute_reply.started":"2025-04-13T13:34:18.599190Z","shell.execute_reply":"2025-04-13T13:34:18.602210Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"# ---- Transforms ----\ntransform = transforms.Compose([\n    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n    transforms.ToTensor()\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T13:34:31.088218Z","iopub.execute_input":"2025-04-13T13:34:31.089104Z","iopub.status.idle":"2025-04-13T13:34:31.093090Z","shell.execute_reply.started":"2025-04-13T13:34:31.089073Z","shell.execute_reply":"2025-04-13T13:34:31.092307Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"# import kagglehub\n\n# # Download latest version\n# path = kagglehub.dataset_download(\"birdy654/cifake-real-and-ai-generated-synthetic-images\")\n\n# print(\"Path to dataset files:\", path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T13:27:43.922662Z","iopub.execute_input":"2025-04-13T13:27:43.922991Z","iopub.status.idle":"2025-04-13T13:27:46.994541Z","shell.execute_reply.started":"2025-04-13T13:27:43.922970Z","shell.execute_reply":"2025-04-13T13:27:46.993813Z"}},"outputs":[{"name":"stdout","text":"Path to dataset files: /kaggle/input/cifake-real-and-ai-generated-synthetic-images\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# ---- Dataset Load ----\nfull_train_dataset = datasets.ImageFolder('/kaggle/input/cifake-real-and-ai-generated-synthetic-images/train', transform=transform)\nclass_map = full_train_dataset.class_to_idx\nprint(\"Class Mapping:\", class_map)\nreal_idx = class_map['REAL']\nfake_idx = class_map['FAKE']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T13:35:04.965216Z","iopub.execute_input":"2025-04-13T13:35:04.965719Z","iopub.status.idle":"2025-04-13T13:36:11.130776Z","shell.execute_reply.started":"2025-04-13T13:35:04.965695Z","shell.execute_reply":"2025-04-13T13:36:11.130066Z"}},"outputs":[{"name":"stdout","text":"Class Mapping: {'FAKE': 0, 'REAL': 1}\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"def remap_targets(dataset):\n    for i in range(len(dataset.targets)):\n        if dataset.targets[i] == fake_idx:\n            dataset.targets[i] = 1\n        elif dataset.targets[i] == real_idx:\n            dataset.targets[i] = 0\n\nremap_targets(full_train_dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T13:36:11.132057Z","iopub.execute_input":"2025-04-13T13:36:11.132389Z","iopub.status.idle":"2025-04-13T13:36:11.143464Z","shell.execute_reply.started":"2025-04-13T13:36:11.132370Z","shell.execute_reply":"2025-04-13T13:36:11.142887Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"# ---- Split into Train and Val ----\ntrain_len = int(0.8 * len(full_train_dataset))\nval_len = len(full_train_dataset) - train_len\ntrain_dataset, val_dataset = random_split(full_train_dataset, [train_len, val_len])\n\ntrain_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\nval_loader   = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T13:36:11.144059Z","iopub.execute_input":"2025-04-13T13:36:11.144248Z","iopub.status.idle":"2025-04-13T13:36:11.175020Z","shell.execute_reply.started":"2025-04-13T13:36:11.144234Z","shell.execute_reply":"2025-04-13T13:36:11.174486Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"# ---- Test Set ----\ntest_dataset = datasets.ImageFolder('/kaggle/input/cifake-real-and-ai-generated-synthetic-images/test', transform=transform)\nremap_targets(test_dataset)\ntest_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T13:36:34.893618Z","iopub.execute_input":"2025-04-13T13:36:34.894437Z","iopub.status.idle":"2025-04-13T13:36:50.539413Z","shell.execute_reply.started":"2025-04-13T13:36:34.894411Z","shell.execute_reply":"2025-04-13T13:36:50.538855Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"# ---- Hybrid Model ----\nclass HybridModel(nn.Module):\n    def __init__(self):\n        super(HybridModel, self).__init__()\n        self.cnn = nn.Sequential(\n            nn.Conv2d(3, 64, 3, padding=1), nn.ReLU(),\n            nn.Conv2d(64, 128, 3, padding=1), nn.ReLU(),\n            nn.MaxPool2d(2),\n            nn.Conv2d(128, 256, 3, padding=1), nn.ReLU(),\n            nn.MaxPool2d(2)\n        )\n        self.patch_embed = nn.Conv2d(256, 128, kernel_size=4, stride=4)\n        self.transformer = nn.TransformerEncoder(\n            nn.TransformerEncoderLayer(d_model=128, nhead=4, dim_feedforward=256),\n            num_layers=2\n        )\n        self.classifier = nn.Linear(128, NUM_CLASSES)\n\n    def forward(self, x):\n        x = self.cnn(x)\n        x = self.patch_embed(x)         # [B, 128, 8, 8]\n        x = x.flatten(2).permute(2, 0, 1)  # [64, B, 128]\n        x = self.transformer(x)         # [64, B, 128]\n        x = x.mean(dim=0)               # [B, 128]\n        return self.classifier(x)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T13:36:50.540622Z","iopub.execute_input":"2025-04-13T13:36:50.540889Z","iopub.status.idle":"2025-04-13T13:36:50.546743Z","shell.execute_reply.started":"2025-04-13T13:36:50.540865Z","shell.execute_reply":"2025-04-13T13:36:50.546051Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"# ---- Train & Eval Functions ----\ndef train(model, loader, optimizer, criterion):\n    model.train()\n    running_loss, correct = 0, 0\n    for x, y in tqdm(loader, desc=\"Training\"):\n        x, y = x.to(device), y.to(device)\n        optimizer.zero_grad()\n        out = model(x)\n        loss = criterion(out, y)\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item()\n        correct += (out.argmax(1) == y).sum().item()\n    acc = correct / len(loader.dataset)\n    return running_loss / len(loader), acc","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T13:36:50.547324Z","iopub.execute_input":"2025-04-13T13:36:50.547501Z","iopub.status.idle":"2025-04-13T13:36:50.571052Z","shell.execute_reply.started":"2025-04-13T13:36:50.547486Z","shell.execute_reply":"2025-04-13T13:36:50.570230Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"def evaluate(model, loader, criterion):\n    model.eval()\n    loss, correct = 0, 0\n    with torch.no_grad():\n        for x, y in loader:\n            x, y = x.to(device), y.to(device)\n            out = model(x)\n            loss += criterion(out, y).item()\n            correct += (out.argmax(1) == y).sum().item()\n    acc = correct / len(loader.dataset)\n    return loss / len(loader), acc\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T13:36:59.378279Z","iopub.execute_input":"2025-04-13T13:36:59.378897Z","iopub.status.idle":"2025-04-13T13:36:59.383743Z","shell.execute_reply.started":"2025-04-13T13:36:59.378874Z","shell.execute_reply":"2025-04-13T13:36:59.382976Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"# ---- Training ----\nmodel = HybridModel().to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\ncriterion = nn.CrossEntropyLoss()\n\nfor epoch in range(EPOCHS):\n    print(f\"\\nEpoch {epoch+1}/{EPOCHS}\")\n    train_loss, train_acc = train(model, train_loader, optimizer, criterion)\n    val_loss, val_acc = evaluate(model, val_loader, criterion)\n    print(f\"Train Acc: {train_acc:.4f} | Val Acc: {val_acc:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T13:37:09.747521Z","iopub.execute_input":"2025-04-13T13:37:09.748286Z","iopub.status.idle":"2025-04-13T14:07:06.693881Z","shell.execute_reply.started":"2025-04-13T13:37:09.748252Z","shell.execute_reply":"2025-04-13T14:07:06.693163Z"}},"outputs":[{"name":"stdout","text":"\nEpoch 1/5\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 1250/1250 [07:36<00:00,  2.74it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Acc: 0.8080 | Val Acc: 0.9019\n\nEpoch 2/5\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 1250/1250 [04:50<00:00,  4.30it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Acc: 0.9062 | Val Acc: 0.9190\n\nEpoch 3/5\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 1250/1250 [04:28<00:00,  4.65it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Acc: 0.9246 | Val Acc: 0.9278\n\nEpoch 4/5\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 1250/1250 [04:22<00:00,  4.76it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Acc: 0.9325 | Val Acc: 0.9406\n\nEpoch 5/5\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 1250/1250 [04:22<00:00,  4.77it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Acc: 0.9413 | Val Acc: 0.9459\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"# ---- Testing ----\nmodel.eval()\ny_true = []\ny_pred = []\n\nwith torch.no_grad():\n    for x, y in tqdm(test_loader, desc=\"Testing\"):\n        x = x.to(device)\n        out = model(x)\n        preds = out.argmax(1).cpu()\n        y_true.extend(y.numpy())\n        y_pred.extend(preds.numpy())\n\nprint(\"\\nTest Classification Report:\")\nprint(classification_report(y_true, y_pred, target_names=[\"REAL\", \"FAKE\"]))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T14:07:06.695253Z","iopub.execute_input":"2025-04-13T14:07:06.695818Z","iopub.status.idle":"2025-04-13T14:09:06.131668Z","shell.execute_reply.started":"2025-04-13T14:07:06.695793Z","shell.execute_reply":"2025-04-13T14:09:06.130970Z"}},"outputs":[{"name":"stderr","text":"Testing: 100%|██████████| 313/313 [01:59<00:00,  2.62it/s]","output_type":"stream"},{"name":"stdout","text":"\nTest Classification Report:\n              precision    recall  f1-score   support\n\n        REAL       0.95      0.93      0.94     10000\n        FAKE       0.93      0.95      0.94     10000\n\n    accuracy                           0.94     20000\n   macro avg       0.94      0.94      0.94     20000\nweighted avg       0.94      0.94      0.94     20000\n\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"# ---- Save ----\ntorch.save(model.state_dict(), \"hybrid_cifake.pth\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T14:17:15.610304Z","iopub.execute_input":"2025-04-13T14:17:15.610621Z","iopub.status.idle":"2025-04-13T14:17:15.627830Z","shell.execute_reply.started":"2025-04-13T14:17:15.610598Z","shell.execute_reply":"2025-04-13T14:17:15.627005Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"# # 1. Make sure the architecture is defined (HybridModel class must be included above or imported)\n# model = HybridModel().to(device)\n\n# # 2. Load the saved weights\n# model.load_state_dict(torch.load(\"hybrid_cifake.pth\", map_location=device))\n\n# # 3. Set to evaluation mode\n# model.eval()","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}