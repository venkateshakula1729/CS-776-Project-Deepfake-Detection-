{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":5256696,"sourceType":"datasetVersion","datasetId":3041726},{"sourceType":"kernelVersion","sourceId":164293490}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Hybrid CNN + Transformer for CIFAKE (Notebook Style)\nimport numpy as np\nimport torch\nimport torch.nn as nn\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader, random_split\nimport torch.nn.functional as F\nfrom tqdm import tqdm  # <-- added for progress bar\nfrom sklearn.metrics import classification_report\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-19T22:32:59.933361Z","iopub.execute_input":"2025-04-19T22:32:59.934022Z","iopub.status.idle":"2025-04-19T22:32:59.937851Z","shell.execute_reply.started":"2025-04-19T22:32:59.933996Z","shell.execute_reply":"2025-04-19T22:32:59.937168Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"# ---- Setup ----\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nBATCH_SIZE = 64\nEPOCHS = 10\nIMG_SIZE = 128\nNUM_CLASSES = 2","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T20:36:45.915892Z","iopub.execute_input":"2025-04-19T20:36:45.916475Z","iopub.status.idle":"2025-04-19T20:36:45.985563Z","shell.execute_reply.started":"2025-04-19T20:36:45.916441Z","shell.execute_reply":"2025-04-19T20:36:45.984606Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# ---- Transforms ----\ntransform = transforms.Compose([\n    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n    transforms.ToTensor()\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T20:36:48.804378Z","iopub.execute_input":"2025-04-19T20:36:48.805154Z","iopub.status.idle":"2025-04-19T20:36:48.808938Z","shell.execute_reply.started":"2025-04-19T20:36:48.805128Z","shell.execute_reply":"2025-04-19T20:36:48.808123Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"import kagglehub\n\n# Download latest version\npath = kagglehub.dataset_download(\"birdy654/cifake-real-and-ai-generated-synthetic-images\")\n\nprint(\"Path to dataset files:\", path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T20:36:57.051052Z","iopub.execute_input":"2025-04-19T20:36:57.051563Z","iopub.status.idle":"2025-04-19T20:36:57.294430Z","shell.execute_reply.started":"2025-04-19T20:36:57.051537Z","shell.execute_reply":"2025-04-19T20:36:57.293741Z"}},"outputs":[{"name":"stdout","text":"Path to dataset files: /kaggle/input/cifake-real-and-ai-generated-synthetic-images\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# ---- Dataset Load ----\nfull_train_dataset = datasets.ImageFolder('/kaggle/input/cifake-real-and-ai-generated-synthetic-images/train', transform=transform)\nclass_map = full_train_dataset.class_to_idx\nprint(\"Class Mapping:\", class_map)\nreal_idx = class_map['REAL']\nfake_idx = class_map['FAKE']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T20:37:01.252316Z","iopub.execute_input":"2025-04-19T20:37:01.252890Z","iopub.status.idle":"2025-04-19T20:40:18.694070Z","shell.execute_reply.started":"2025-04-19T20:37:01.252865Z","shell.execute_reply":"2025-04-19T20:40:18.693417Z"}},"outputs":[{"name":"stdout","text":"Class Mapping: {'FAKE': 0, 'REAL': 1}\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"def remap_targets(dataset):\n    for i in range(len(dataset.targets)):\n        if dataset.targets[i] == fake_idx:\n            dataset.targets[i] = 1\n        elif dataset.targets[i] == real_idx:\n            dataset.targets[i] = 0\n\nremap_targets(full_train_dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T20:55:58.702134Z","iopub.execute_input":"2025-04-19T20:55:58.702963Z","iopub.status.idle":"2025-04-19T20:55:58.713162Z","shell.execute_reply.started":"2025-04-19T20:55:58.702927Z","shell.execute_reply":"2025-04-19T20:55:58.712449Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# ---- Split into Train and Val ----\ntrain_len = int(0.8 * len(full_train_dataset))\nval_len = len(full_train_dataset) - train_len\ntrain_dataset, val_dataset = random_split(full_train_dataset, [train_len, val_len])\n\ntrain_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\nval_loader   = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T20:56:01.635330Z","iopub.execute_input":"2025-04-19T20:56:01.636009Z","iopub.status.idle":"2025-04-19T20:56:01.669899Z","shell.execute_reply.started":"2025-04-19T20:56:01.635984Z","shell.execute_reply":"2025-04-19T20:56:01.669165Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# ---- Test Set ----\ntest_dataset = datasets.ImageFolder('/kaggle/input/cifake-real-and-ai-generated-synthetic-images/test', transform=transform)\nremap_targets(test_dataset)\ntest_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T20:56:05.447980Z","iopub.execute_input":"2025-04-19T20:56:05.448652Z","iopub.status.idle":"2025-04-19T20:56:42.797315Z","shell.execute_reply.started":"2025-04-19T20:56:05.448627Z","shell.execute_reply":"2025-04-19T20:56:42.796778Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# ---- Hybrid Model ----\nclass HybridModel(nn.Module):\n    def __init__(self):\n        super(HybridModel, self).__init__()\n        self.cnn = nn.Sequential(\n            nn.Conv2d(3, 64, 3, padding=1), nn.ReLU(),\n            nn.Conv2d(64, 128, 3, padding=1), nn.ReLU(),\n            nn.MaxPool2d(2),\n            nn.Conv2d(128, 256, 3, padding=1), nn.ReLU(),\n            nn.MaxPool2d(2)\n        )\n        self.patch_embed = nn.Conv2d(256, 128, kernel_size=4, stride=4)\n        self.transformer = nn.TransformerEncoder(\n            nn.TransformerEncoderLayer(d_model=128, nhead=4, dim_feedforward=256),\n            num_layers=2\n        )\n        self.classifier = nn.Linear(128, NUM_CLASSES)\n\n    def forward(self, x):\n        x = self.cnn(x)\n        x = self.patch_embed(x)         # [B, 128, 8, 8]\n        x = x.flatten(2).permute(2, 0, 1)  # [64, B, 128]\n        x = self.transformer(x)         # [64, B, 128]\n        x = x.mean(dim=0)               # [B, 128]\n        return self.classifier(x)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T20:57:48.072353Z","iopub.execute_input":"2025-04-19T20:57:48.072923Z","iopub.status.idle":"2025-04-19T20:57:48.078883Z","shell.execute_reply.started":"2025-04-19T20:57:48.072901Z","shell.execute_reply":"2025-04-19T20:57:48.078126Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# ---- Train & Eval Functions ----\ndef train(model, loader, optimizer, criterion):\n    model.train()\n    running_loss, correct = 0, 0\n    for x, y in tqdm(loader, desc=\"Training\"):\n        x, y = x.to(device), y.to(device)\n        optimizer.zero_grad()\n        out = model(x)\n        loss = criterion(out, y)\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item()\n        correct += (out.argmax(1) == y).sum().item()\n    acc = correct / len(loader.dataset)\n    return running_loss / len(loader), acc","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T20:57:51.559528Z","iopub.execute_input":"2025-04-19T20:57:51.559783Z","iopub.status.idle":"2025-04-19T20:57:51.564625Z","shell.execute_reply.started":"2025-04-19T20:57:51.559758Z","shell.execute_reply":"2025-04-19T20:57:51.563935Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"def evaluate(model, loader, criterion):\n    model.eval()\n    loss, correct = 0, 0\n    with torch.no_grad():\n        for x, y in loader:\n            x, y = x.to(device), y.to(device)\n            out = model(x)\n            loss += criterion(out, y).item()\n            correct += (out.argmax(1) == y).sum().item()\n    acc = correct / len(loader.dataset)\n    return loss / len(loader), acc\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T20:57:57.125765Z","iopub.execute_input":"2025-04-19T20:57:57.126014Z","iopub.status.idle":"2025-04-19T20:57:57.130429Z","shell.execute_reply.started":"2025-04-19T20:57:57.125998Z","shell.execute_reply":"2025-04-19T20:57:57.129750Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"# ---- Training ----\nmodel = HybridModel().to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\ncriterion = nn.CrossEntropyLoss()\n\nfor epoch in range(EPOCHS):\n    print(f\"\\nEpoch {epoch+1}/{EPOCHS}\")\n    train_loss, train_acc = train(model, train_loader, optimizer, criterion)\n    val_loss, val_acc = evaluate(model, val_loader, criterion)\n    print(f\"Train Acc: {train_acc:.4f} | Val Acc: {val_acc:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T20:57:59.277972Z","iopub.execute_input":"2025-04-19T20:57:59.278709Z","iopub.status.idle":"2025-04-19T21:56:23.660196Z","shell.execute_reply.started":"2025-04-19T20:57:59.278684Z","shell.execute_reply":"2025-04-19T21:56:23.659418Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1/10\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 1250/1250 [12:58<00:00,  1.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Acc: 0.8054 | Val Acc: 0.8879\n\nEpoch 2/10\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 1250/1250 [04:50<00:00,  4.30it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Acc: 0.9061 | Val Acc: 0.9225\n\nEpoch 3/10\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 1250/1250 [04:02<00:00,  5.16it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Acc: 0.9230 | Val Acc: 0.9191\n\nEpoch 4/10\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 1250/1250 [04:03<00:00,  5.14it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Acc: 0.9333 | Val Acc: 0.9358\n\nEpoch 5/10\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 1250/1250 [04:01<00:00,  5.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Acc: 0.9401 | Val Acc: 0.9148\n\nEpoch 6/10\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 1250/1250 [04:01<00:00,  5.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Acc: 0.9461 | Val Acc: 0.9443\n\nEpoch 7/10\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 1250/1250 [04:01<00:00,  5.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Acc: 0.9504 | Val Acc: 0.9424\n\nEpoch 8/10\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 1250/1250 [04:00<00:00,  5.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Acc: 0.9554 | Val Acc: 0.9462\n\nEpoch 9/10\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 1250/1250 [04:02<00:00,  5.15it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Acc: 0.9588 | Val Acc: 0.9504\n\nEpoch 10/10\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 1250/1250 [04:04<00:00,  5.11it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Acc: 0.9624 | Val Acc: 0.9539\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"# ---- Testing ----\nmodel.eval()\ny_true = []\ny_pred = []\n\nwith torch.no_grad():\n    for x, y in tqdm(test_loader, desc=\"Testing\"):\n        x = x.to(device)\n        out = model(x)\n        preds = out.argmax(1).cpu()\n        y_true.extend(y.numpy())\n        y_pred.extend(preds.numpy())\n\nprint(\"\\nTest Classification Report:\")\nprint(classification_report(y_true, y_pred, target_names=[\"REAL\", \"FAKE\"]))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T21:56:41.787182Z","iopub.execute_input":"2025-04-19T21:56:41.787653Z","iopub.status.idle":"2025-04-19T21:59:24.122886Z","shell.execute_reply.started":"2025-04-19T21:56:41.787628Z","shell.execute_reply":"2025-04-19T21:59:24.122187Z"}},"outputs":[{"name":"stderr","text":"Testing: 100%|██████████| 313/313 [02:42<00:00,  1.93it/s]","output_type":"stream"},{"name":"stdout","text":"\nTest Classification Report:\n              precision    recall  f1-score   support\n\n        REAL       0.94      0.97      0.95     10000\n        FAKE       0.96      0.94      0.95     10000\n\n    accuracy                           0.95     20000\n   macro avg       0.95      0.95      0.95     20000\nweighted avg       0.95      0.95      0.95     20000\n\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"accuracy = (np.array(y_true) == np.array(y_pred)).mean()\nprint(f\"\\nTest Accuracy: {accuracy * 100:.2f}%\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T22:33:17.480225Z","iopub.execute_input":"2025-04-19T22:33:17.480904Z","iopub.status.idle":"2025-04-19T22:33:17.487450Z","shell.execute_reply.started":"2025-04-19T22:33:17.480881Z","shell.execute_reply":"2025-04-19T22:33:17.486877Z"}},"outputs":[{"name":"stdout","text":"\nTest Accuracy: 95.03%\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"# ---- Save ----\ntorch.save(model.state_dict(), \"hybrid_baseline_cifake.pth\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T22:00:38.787209Z","iopub.execute_input":"2025-04-19T22:00:38.787775Z","iopub.status.idle":"2025-04-19T22:00:38.803604Z","shell.execute_reply.started":"2025-04-19T22:00:38.787752Z","shell.execute_reply":"2025-04-19T22:00:38.802856Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"# Adversarial Attack Functions\ndef fgsm_attack(model, images, labels, epsilon=0.05):\n    images.requires_grad = True\n    outputs = model(images)\n    loss = F.cross_entropy(outputs, labels)\n    model.zero_grad()\n    loss.backward()\n    \n    # Create adversarial examples\n    attack_images = images + epsilon * images.grad.sign()\n    attack_images = torch.clamp(attack_images, 0, 1)\n    return attack_images.detach()\n\ndef pgd_attack(model, images, labels, epsilon=0.03, alpha=0.01, iters=10):\n    original_images = images.clone().detach()\n    \n    for _ in range(iters):\n        images.requires_grad = True\n        outputs = model(images)\n        loss = F.cross_entropy(outputs, labels)\n        model.zero_grad()\n        loss.backward()\n        \n        adv_images = images + alpha * images.grad.sign()\n        eta = torch.clamp(adv_images - original_images, min=-epsilon, max=epsilon)\n        images = torch.clamp(original_images + eta, 0, 1).detach()\n    \n    return images\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T22:00:43.170062Z","iopub.execute_input":"2025-04-19T22:00:43.170539Z","iopub.status.idle":"2025-04-19T22:00:43.176047Z","shell.execute_reply.started":"2025-04-19T22:00:43.170518Z","shell.execute_reply":"2025-04-19T22:00:43.175331Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"\n# Adversarial Evaluation Function\ndef evaluate_attacks(model, loader, attack_fn, **attack_kwargs):\n    model.eval()\n    correct = 0\n    total = 0\n    \n    for images, labels in tqdm(loader, desc=\"Evaluating Attacks\"):\n        images, labels = images.to(device), labels.to(device)\n        \n        # Generate adversarial examples\n        adv_images = attack_fn(model, images, labels, **attack_kwargs)\n        \n        # Evaluate on adversarial examples\n        outputs = model(adv_images)\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n    \n    accuracy = 100 * correct / total\n    return accuracy\n\n# Load your trained model\nmodel = HybridModel().to(device)\nmodel.load_state_dict(torch.load(\"hybrid_baseline_cifake.pth\", map_location=device))\nmodel.eval()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T22:32:30.983575Z","iopub.execute_input":"2025-04-19T22:32:30.983843Z","iopub.status.idle":"2025-04-19T22:32:31.016699Z","shell.execute_reply.started":"2025-04-19T22:32:30.983823Z","shell.execute_reply":"2025-04-19T22:32:31.015965Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_31/2690867178.py:24: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model.load_state_dict(torch.load(\"hybrid_baseline_cifake.pth\", map_location=device))\n","output_type":"stream"},{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"HybridModel(\n  (cnn): Sequential(\n    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): ReLU()\n    (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (3): ReLU()\n    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (5): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (6): ReLU()\n    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (patch_embed): Conv2d(256, 128, kernel_size=(4, 4), stride=(4, 4))\n  (transformer): TransformerEncoder(\n    (layers): ModuleList(\n      (0-1): 2 x TransformerEncoderLayer(\n        (self_attn): MultiheadAttention(\n          (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n        )\n        (linear1): Linear(in_features=128, out_features=256, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n        (linear2): Linear(in_features=256, out_features=128, bias=True)\n        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n        (dropout1): Dropout(p=0.1, inplace=False)\n        (dropout2): Dropout(p=0.1, inplace=False)\n      )\n    )\n  )\n  (classifier): Linear(in_features=128, out_features=2, bias=True)\n)"},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"\n# Evaluate against FGSM attacks\nprint(\"\\nEvaluating FGSM Attacks:\")\nfor epsilon in [0.01, 0.03, 0.05]:\n    fgsm_acc = evaluate_attacks(model, test_loader, fgsm_attack, epsilon=epsilon)\n    print(f\"FGSM (ε={epsilon}): Accuracy = {fgsm_acc:.2f}%\")\n\n# Evaluate against PGD attacks\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T22:00:57.259613Z","iopub.execute_input":"2025-04-19T22:00:57.259886Z","iopub.status.idle":"2025-04-19T22:11:19.576735Z","shell.execute_reply.started":"2025-04-19T22:00:57.259867Z","shell.execute_reply":"2025-04-19T22:11:19.576045Z"}},"outputs":[{"name":"stdout","text":"\nEvaluating FGSM Attacks:\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Attacks: 100%|██████████| 313/313 [01:13<00:00,  4.25it/s]\n","output_type":"stream"},{"name":"stdout","text":"FGSM (ε=0.01): Accuracy = 26.54%\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Attacks: 100%|██████████| 313/313 [01:13<00:00,  4.27it/s]\n","output_type":"stream"},{"name":"stdout","text":"FGSM (ε=0.03): Accuracy = 10.21%\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Attacks: 100%|██████████| 313/313 [01:14<00:00,  4.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"FGSM (ε=0.05): Accuracy = 20.05%\n\nEvaluating PGD Attacks:\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Attacks: 100%|██████████| 313/313 [06:41<00:00,  1.28s/it]","output_type":"stream"},{"name":"stdout","text":"PGD : Accuracy = 0.03%\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":20}]}