{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":5256696,"sourceType":"datasetVersion","datasetId":3041726}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# ✅ Imports","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.applications.vgg19 import VGG19, preprocess_input\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Flatten, Dense, Dropout\nfrom tensorflow.keras.models import load_model\nimport numpy as np\nimport os\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-12T09:02:02.255723Z","iopub.execute_input":"2025-04-12T09:02:02.256936Z","iopub.status.idle":"2025-04-12T09:02:02.263026Z","shell.execute_reply.started":"2025-04-12T09:02:02.256911Z","shell.execute_reply":"2025-04-12T09:02:02.262155Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"os.listdir('/kaggle/input') ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-12T09:02:02.264633Z","iopub.execute_input":"2025-04-12T09:02:02.264971Z","iopub.status.idle":"2025-04-12T09:02:02.290994Z","shell.execute_reply.started":"2025-04-12T09:02:02.264953Z","shell.execute_reply":"2025-04-12T09:02:02.290266Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"['cifake-real-and-ai-generated-synthetic-images']"},"metadata":{}}],"execution_count":11},{"cell_type":"markdown","source":"# ✅ Model Builder","metadata":{}},{"cell_type":"code","source":"def build_vgg19():\n    base = VGG19(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n    for layer in base.layers:\n        layer.trainable = False\n    x = Flatten()(base.output)\n    x = Dense(256, activation='relu')(x)\n    x = Dropout(0.5)(x)\n    out = Dense(1, activation='sigmoid')(x)\n    return Model(base.input, out)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-12T09:02:02.291731Z","iopub.execute_input":"2025-04-12T09:02:02.292055Z","iopub.status.idle":"2025-04-12T09:02:02.308518Z","shell.execute_reply.started":"2025-04-12T09:02:02.292035Z","shell.execute_reply":"2025-04-12T09:02:02.307882Z"}},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"# ✅ Data Generators","metadata":{}},{"cell_type":"code","source":"import shutil\nfrom sklearn.model_selection import train_test_split\n\nbase_dir = \"/kaggle/input/cifake-real-and-ai-generated-synthetic-images/train\"\nval_dir = \"/kaggle/working/validation\"\n\nfor label in ['REAL', 'FAKE']:\n    os.makedirs(os.path.join(val_dir, label), exist_ok=True)\n    files = os.listdir(os.path.join(base_dir, label))\n    train_files, val_files = train_test_split(files, test_size=0.2, random_state=42)\n\n    for fname in val_files:\n        src = os.path.join(base_dir, label, fname)\n        dst = os.path.join(val_dir, label, fname)\n        shutil.copyfile(src, dst)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-12T09:02:02.309314Z","iopub.execute_input":"2025-04-12T09:02:02.309577Z","iopub.status.idle":"2025-04-12T09:03:08.145510Z","shell.execute_reply.started":"2025-04-12T09:02:02.309559Z","shell.execute_reply":"2025-04-12T09:03:08.144617Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"train_gen = ImageDataGenerator(preprocessing_function=preprocess_input).flow_from_directory(\n    '/kaggle/input/cifake-real-and-ai-generated-synthetic-images/train',\n    target_size=(224, 224), batch_size=32, class_mode='binary', shuffle=True)\n\nval_gen = ImageDataGenerator(preprocessing_function=preprocess_input).flow_from_directory(\n    '/kaggle/working/validation',\n    target_size=(224, 224), batch_size=32, class_mode='binary', shuffle=False)\n\ntest_gen = ImageDataGenerator(preprocessing_function=preprocess_input).flow_from_directory(\n    '/kaggle/input/cifake-real-and-ai-generated-synthetic-images/test',\n    target_size=(224, 224), batch_size=32, class_mode='binary', shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-12T09:03:08.147943Z","iopub.execute_input":"2025-04-12T09:03:08.148232Z","iopub.status.idle":"2025-04-12T09:04:34.998929Z","shell.execute_reply.started":"2025-04-12T09:03:08.148206Z","shell.execute_reply":"2025-04-12T09:04:34.998239Z"}},"outputs":[{"name":"stdout","text":"Found 100000 images belonging to 2 classes.\nFound 20000 images belonging to 2 classes.\nFound 20000 images belonging to 2 classes.\n","output_type":"stream"}],"execution_count":14},{"cell_type":"markdown","source":"# ✅ FGSM Attack Function and PGD Attack Function","metadata":{}},{"cell_type":"code","source":"@tf.function\ndef fgsm_attack(model, images, labels, epsilon=0.05):\n    with tf.GradientTape() as tape:\n        tape.watch(images)\n        predictions = model(images)\n        loss = tf.keras.losses.BinaryCrossentropy()(labels, predictions)\n    gradient = tape.gradient(loss, images)\n    signed_grad = tf.sign(gradient)\n    adv_images = images + epsilon * signed_grad\n    return tf.clip_by_value(adv_images, 0, 1)\n\n# ✅ PGD Attack Function\n@tf.function\ndef pgd_attack(x, y, model, loss_fn, eps=4/255, alpha=1/255, iters=7):\n    x_adv = tf.identity(x)\n    for _ in tf.range(iters):\n        with tf.GradientTape() as tape:\n            tape.watch(x_adv)\n            pred = model(x_adv, training=False)\n            loss = loss_fn(y, pred)\n        grad = tape.gradient(loss, x_adv)\n        x_adv = x_adv + alpha * tf.sign(grad)\n        x_adv = tf.clip_by_value(x_adv, x - eps, x + eps)\n        x_adv = tf.clip_by_value(x_adv, -1.0, 1.0)\n    return x_adv","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-12T09:04:35.000089Z","iopub.execute_input":"2025-04-12T09:04:35.000404Z","iopub.status.idle":"2025-04-12T09:04:35.016141Z","shell.execute_reply.started":"2025-04-12T09:04:35.000376Z","shell.execute_reply":"2025-04-12T09:04:35.015300Z"}},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":"# ✅ Train and Save Baseline Model","metadata":{}},{"cell_type":"code","source":"# Paths to save model and weights\nweights_path_baseline = '/kaggle/working/vgg19_baseline_cifake.weights.h5'\nmodel_path_baseline   = '/kaggle/working/vgg19_baseline_cifake_model.h5'\nif os.path.exists(model_path_baseline):\n    print(\"Loading saved model...\")\n    baseline_model = load_model(model_path_baseline)\nelse:\n    print(\"Training baseline model...\")\n    baseline_model = build_vgg19()\n    baseline_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n    baseline_model.fit(train_gen, epochs=3, validation_data=val_gen)\n    baseline_model.save_weights(weights_path_baseline)\n    baseline_model.save(model_path_baseline)\n    print(\"Baseline model trained and saved.\")\n\nprint(\"\\nEvaluating Baseline Model on Clean Test Set:\")\nbaseline_clean_acc = baseline_model.evaluate(test_gen)\nprint(\"Baseline Clean Accuracy:\", baseline_clean_acc)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-12T09:04:35.017081Z","iopub.execute_input":"2025-04-12T09:04:35.017358Z","iopub.status.idle":"2025-04-12T09:48:56.838864Z","shell.execute_reply.started":"2025-04-12T09:04:35.017341Z","shell.execute_reply":"2025-04-12T09:48:56.838000Z"}},"outputs":[{"name":"stdout","text":"Training baseline model...\n","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1744448678.497597      31 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\nI0000 00:00:1744448678.498416      31 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13942 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n","output_type":"stream"},{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n\u001b[1m80134624/80134624\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\nEpoch 1/3\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1744448686.752826     122 service.cc:148] XLA service 0x7c029800fc60 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1744448686.758094     122 service.cc:156]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\nI0000 00:00:1744448686.758117     122 service.cc:156]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5\nI0000 00:00:1744448687.342868     122 cuda_dnn.cc:529] Loaded cuDNN version 90300\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m   1/3125\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m15:06:27\u001b[0m 17s/step - accuracy: 0.5938 - loss: 2.9820","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1744448699.862714     122 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m849s\u001b[0m 266ms/step - accuracy: 0.8535 - loss: 0.6168 - val_accuracy: 0.9240 - val_loss: 0.1842\nEpoch 2/3\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m825s\u001b[0m 264ms/step - accuracy: 0.9005 - loss: 0.2454 - val_accuracy: 0.9391 - val_loss: 0.1559\nEpoch 3/3\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m826s\u001b[0m 264ms/step - accuracy: 0.9122 - loss: 0.2194 - val_accuracy: 0.9445 - val_loss: 0.1361\nBaseline model trained and saved.\n\nEvaluating Baseline Model on Clean Test Set:\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 245ms/step - accuracy: 0.9280 - loss: 0.1888\nBaseline Clean Accuracy: [0.18823879957199097, 0.9305499792098999]\n","output_type":"stream"}],"execution_count":16},{"cell_type":"markdown","source":"# ✅ FGSM Vulnerability Evaluation","metadata":{}},{"cell_type":"code","source":"x_test_sample, y_test_sample = next(test_gen)\nx_test_tensor = tf.convert_to_tensor(x_test_sample, dtype=tf.float32)\ny_test_tensor = tf.convert_to_tensor(y_test_sample, dtype=tf.float32)\n\nx_fgsm_test = fgsm_attack(baseline_model, x_test_tensor, y_test_tensor)\nprint(\"\\nEvaluating Baseline Model on FGSM-Adversarial Examples:\")\nbaseline_fgsm_acc = baseline_model.evaluate(x_fgsm_test, y_test_sample)\nprint(\"Baseline Accuracy on FGSM-Adversarial:\", baseline_fgsm_acc)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-12T09:48:56.839896Z","iopub.execute_input":"2025-04-12T09:48:56.840576Z","iopub.status.idle":"2025-04-12T09:49:06.717574Z","shell.execute_reply.started":"2025-04-12T09:48:56.840544Z","shell.execute_reply":"2025-04-12T09:49:06.716874Z"}},"outputs":[{"name":"stdout","text":"\nEvaluating Baseline Model on FGSM-Adversarial Examples:\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255ms/step - accuracy: 0.8438 - loss: 0.3812\nBaseline Accuracy on FGSM-Adversarial: [0.3812202513217926, 0.84375]\n","output_type":"stream"}],"execution_count":17},{"cell_type":"markdown","source":"# ✅ Adversarial Training with FGSM + PGD","metadata":{}},{"cell_type":"code","source":"# Paths\nadv_weights_path = '/kaggle/working/vgg19_adv_trained.weights.h5'\nadv_model_path   = '/kaggle/working/vgg19_adv_trained_model.h5'\n\n# Load if already saved\nif os.path.exists(adv_model_path):\n    print(\"Loading saved adversarially trained model...\")\n    adv_model = load_model(adv_model_path)\nelse:\n    print(\"Training adversarially robust model...\")\n    adv_model = build_vgg19()\n    optimizer = tf.keras.optimizers.Adam(1e-4)\n    loss_fn = tf.keras.losses.BinaryCrossentropy()\n\n    epochs = 3\n    train_steps = train_gen.samples // train_gen.batch_size\n    val_steps = val_gen.samples // val_gen.batch_size\n\n    for epoch in range(epochs):\n        print(f\"\\nEpoch {epoch+1}/{epochs}\")\n        for step in range(train_steps):\n            x_batch, y_batch = next(train_gen)\n            x_tensor = tf.convert_to_tensor(x_batch, dtype=tf.float32)\n            y_tensor = tf.convert_to_tensor(y_batch, dtype=tf.float32)\n\n            adv_count = x_tensor.shape[0] // 2\n            x_fgsm = fgsm_attack(adv_model, x_tensor[:adv_count], y_tensor[:adv_count])\n            x_pgd = pgd_attack(x_tensor[adv_count:], y_tensor[adv_count:], adv_model, loss_fn)\n\n            x_mix = tf.concat([x_fgsm, x_pgd], axis=0)\n            y_mix = y_tensor\n\n            with tf.GradientTape() as tape:\n                preds = adv_model(x_mix, training=True)\n                loss = loss_fn(y_mix, preds)\n            grads = tape.gradient(loss, adv_model.trainable_variables)\n            optimizer.apply_gradients(zip(grads, adv_model.trainable_variables))\n\n        val_acc = tf.keras.metrics.BinaryAccuracy()\n        for _ in range(val_steps):\n            xv, yv = next(val_gen)\n            val_acc.update_state(yv, adv_model(xv, training=False))\n        print(\"Validation Accuracy:\", val_acc.result().numpy())\n\n    print(\"\\nTraining done. Saving adversarially trained model...\")\n    adv_model.save_weights(adv_weights_path)\n    adv_model.save(adv_model_path)\n\n# Evaluation (done in both cases)\nprint(\"Evaluating Adv-Trained Model on Clean Test Set:\")\nadv_clean_acc = adv_model.evaluate(test_gen)\nprint(\"Adversarially Trained Accuracy on Clean Test:\", adv_clean_acc)\n\nx_adv_fgsm_eval = fgsm_attack(adv_model, x_test_tensor, y_test_tensor)\nprint(\"Evaluating Adv-Trained Model on FGSM-Adversarial Examples:\")\nadv_fgsm_acc = adv_model.evaluate(x_adv_fgsm_eval, y_test_sample)\nprint(\"Adv-Trained Accuracy on FGSM-Adversarial:\", adv_fgsm_acc)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-12T09:49:06.718489Z","iopub.execute_input":"2025-04-12T09:49:06.718891Z"}},"outputs":[{"name":"stdout","text":"Training adversarially robust model...\n\nEpoch 1/3\n","output_type":"stream"},{"name":"stderr","text":"E0000 00:00:1744451352.022107      31 meta_optimizer.cc:966] layout failed: INVALID_ARGUMENT: MutableGraphView::SortTopologically error: detected edge(s) creating cycle(s) {'while/body/_1/while/Identity_3' -> 'while/next_iteration/_76'}.\n","output_type":"stream"}],"execution_count":null},{"cell_type":"markdown","source":"# ✅ Evaluate and Save Adversarially Trained Model","metadata":{}},{"cell_type":"code","source":"print(\"Evaluating Adv-Trained Model on Clean Test Set:\")\nadv_clean_acc = adv_model.evaluate(test_gen)\nprint(\"Adversarially Trained Accuracy on Clean Test:\", adv_clean_acc)\n    \nx_adv_fgsm_eval = fgsm_attack(adv_model, x_test_tensor, y_test_tensor)\nprint(\"Evaluating Adv-Trained Model on FGSM-Adversarial Examples:\")\nadv_fgsm_acc = adv_model.evaluate(x_adv_fgsm_eval, y_test_sample)\nprint(\"Adv-Trained Accuracy on FGSM-Adversarial:\", adv_fgsm_acc)\n    \n# ✅ Save adversarially trained model\nadv_model.save_weights('/kaggle/working/vgg19_adv_trained.weights.h5')\nadv_model.save('/kaggle/working/vgg19_adv_trained_model.h5')\nprint(\"Adversarially trained model saved.\")\nprint(\"Adv-Trained Accuracy on FGSM-Adversarial:\", adv_fgsm_acc)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}