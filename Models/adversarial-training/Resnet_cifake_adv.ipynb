{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":5256696,"sourceType":"datasetVersion","datasetId":3041726}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\n\ngpus = tf.config.list_physical_devices('GPU')\nif gpus:\n    for gpu in gpus:\n        tf.config.experimental.set_memory_growth(gpu, True)\n    print(f\"[GPU setup] {len(gpus)} Physical GPU(s) with memory growth enabled.\")\nelse:\n    print(\"[GPU setup] No GPU found, using CPU.\")\nimport os\nimport warnings\nwarnings.filterwarnings('ignore')\n\n\n# Core libraries\nimport numpy as np\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Model, load_model\nfrom tensorflow.keras.layers import Flatten, Dense, Dropout\nfrom tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input  # Changed to ResNet\nfrom sklearn.model_selection import train_test_split\nfrom tqdm import tqdm","metadata":{"_uuid":"a9625d2c-0d25-4765-9c4d-2cb22d2baae1","_cell_guid":"47210957-0001-48a2-8411-1fd13dec6d53","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-04-19T20:04:07.340508Z","iopub.execute_input":"2025-04-19T20:04:07.340693Z","iopub.status.idle":"2025-04-19T20:04:07.348177Z","shell.execute_reply.started":"2025-04-19T20:04:07.340678Z","shell.execute_reply":"2025-04-19T20:04:07.347457Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","text":"[GPU setup] 1 Physical GPU(s) with memory growth enabled.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"# Build Pretrained ResNet50 Model","metadata":{"_uuid":"dccf7079-4b9b-439f-bd58-6ae547fa20f3","_cell_guid":"9cc1cb39-553c-467e-a3c8-575450c20dc7","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"def build_resnet(dropout_rate=0.5):  \n    base = ResNet50(weights='imagenet', include_top=False,\n                   input_shape=(224, 224, 3))  \n    for layer in base.layers:\n        layer.trainable = False\n\n    x = Flatten()(base.output)\n    x = Dense(256, activation='relu')(x)\n    x = Dropout(dropout_rate)(x)\n    out = Dense(1, activation='sigmoid')(x)\n\n    model = Model(inputs=base.input, outputs=out)\n    return model","metadata":{"_uuid":"337b63b0-c2e2-4d00-81e2-4a4f2c17dc52","_cell_guid":"ef70ea4f-4a70-4298-a8f2-975269b77021","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-04-19T20:04:21.879628Z","iopub.execute_input":"2025-04-19T20:04:21.879902Z","iopub.status.idle":"2025-04-19T20:04:21.884775Z","shell.execute_reply.started":"2025-04-19T20:04:21.879882Z","shell.execute_reply":"2025-04-19T20:04:21.884016Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"# Prepare Dataset & Generators ","metadata":{"_uuid":"6d20336a-7bed-43fb-b992-b4023d75ba61","_cell_guid":"ae8cd0bf-1223-4ff9-8421-eeb996fc4b74","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"# Paths\nimport os\nimport shutil\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\ndata_dir = \"/kaggle/input/cifake-real-and-ai-generated-synthetic-images/train\"\nval_dir  = \"/kaggle/working/validation\"\n\n# Create validation split\nfor cls in ['REAL', 'FAKE']:\n    os.makedirs(os.path.join(val_dir, cls), exist_ok=True)\n    files = os.listdir(os.path.join(data_dir, cls))\n    _, val_files = train_test_split(files, test_size=0.2, random_state=42)\n    for f in val_files:\n        src = os.path.join(data_dir, cls, f)\n        dst = os.path.join(val_dir, cls, f)\n        shutil.copyfile(src, dst)\n\n# Generators (using ResNet's preprocess_input)\ntrain_gen = ImageDataGenerator(preprocessing_function=preprocess_input).flow_from_directory(\n    data_dir,\n    target_size=(224, 224),\n    batch_size=32,\n    class_mode='binary',\n    shuffle=True\n)\n\nval_gen = ImageDataGenerator(preprocessing_function=preprocess_input).flow_from_directory(\n    val_dir,\n    target_size=(224, 224),\n    batch_size=32,\n    class_mode='binary',\n    shuffle=False\n)\n\ntest_gen = ImageDataGenerator(preprocessing_function=preprocess_input).flow_from_directory(\n    \"/kaggle/input/cifake-real-and-ai-generated-synthetic-images/test\",\n    target_size=(224, 224),\n    batch_size=32,\n    class_mode='binary',\n    shuffle=False\n)","metadata":{"_uuid":"be04fcae-e295-43d0-b367-3cc5a5425719","_cell_guid":"838bdec5-5679-4864-94c2-0f28e873dc58","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-04-19T20:04:36.113957Z","iopub.execute_input":"2025-04-19T20:04:36.114264Z","iopub.status.idle":"2025-04-19T20:07:02.857733Z","shell.execute_reply.started":"2025-04-19T20:04:36.114241Z","shell.execute_reply":"2025-04-19T20:07:02.856990Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","text":"Found 100000 images belonging to 2 classes.\nFound 20000 images belonging to 2 classes.\nFound 20000 images belonging to 2 classes.\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"# Adversarial Attack Functions ","metadata":{"_uuid":"73427d58-83ff-4e4e-b136-b85f1961e6d3","_cell_guid":"1b772def-2e25-4c94-8fa8-4e4fb703c455","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"@tf.function\ndef fgsm_attack(model, images, labels, epsilon=0.05):\n    with tf.GradientTape() as tape:\n        tape.watch(images)\n        preds = model(images)\n        loss = tf.keras.losses.BinaryCrossentropy()(labels, preds)\n    grad = tape.gradient(loss, images)\n    adv = images + epsilon * tf.sign(grad)\n    return tf.clip_by_value(adv, -1.0, 1.0)\n\n@tf.function\ndef pgd_attack(x, y, model, loss_fn,\n               epsilon=0.03, alpha=0.007, iters=10):\n    x_adv = tf.identity(x)\n    for _ in range(iters):\n        with tf.GradientTape() as tape:\n            tape.watch(x_adv)\n            pred = model(x_adv, training=False)\n            loss = loss_fn(y, pred)\n        grad = tape.gradient(loss, x_adv)\n        x_adv = x_adv + alpha * tf.sign(grad)\n        x_adv = tf.clip_by_value(x_adv, x - epsilon, x + epsilon)\n        x_adv = tf.clip_by_value(x_adv, -1.0, 1.0)\n    return x_adv","metadata":{"_uuid":"62fde76d-48f8-480d-ae6c-3f4c98ff17b8","_cell_guid":"b3a61e82-7c83-493b-aedb-950bb193724c","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-04-19T20:09:51.513905Z","iopub.execute_input":"2025-04-19T20:09:51.514444Z","iopub.status.idle":"2025-04-19T20:09:51.521542Z","shell.execute_reply.started":"2025-04-19T20:09:51.514412Z","shell.execute_reply":"2025-04-19T20:09:51.520821Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"# Train & Save Baseline ResNet Model","metadata":{"_uuid":"c4a7e2a1-0036-4025-a6b1-6a23fef377c3","_cell_guid":"6f8659cc-1841-4b1c-bf44-c4781fbcffc6","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"baseline_weights = \"/kaggle/working/resnet_baseline.weights.h5\"  \nbaseline_model_path = \"/kaggle/working/resnet_baseline_model.h5\"  ","metadata":{"_uuid":"a9121f13-a9bf-4751-b8eb-619d2ebe35ba","_cell_guid":"0bef3136-e5f7-4dcc-a681-6f435b760e8e","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-04-19T20:09:55.271757Z","iopub.execute_input":"2025-04-19T20:09:55.272344Z","iopub.status.idle":"2025-04-19T20:09:55.275582Z","shell.execute_reply.started":"2025-04-19T20:09:55.272321Z","shell.execute_reply":"2025-04-19T20:09:55.274909Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"if os.path.exists(baseline_model_path):\n    baseline_model = load_model(baseline_model_path)\n    print(\"Loaded existing baseline model.\")\nelse:\n    baseline_model = build_resnet() \n    baseline_model.compile(optimizer='adam',\n                         loss='binary_crossentropy',\n                         metrics=['accuracy'])\n    baseline_model.fit(\n        train_gen, epochs=3, validation_data=val_gen)\n    baseline_model.save_weights(baseline_weights)\n    baseline_model.save(baseline_model_path)\n    print(\"ResNet baseline model trained and saved.\")  ","metadata":{"_uuid":"10aca8c2-e599-4319-ae4e-0db17f1ebaec","_cell_guid":"33542138-3aa2-4060-83ae-cdaab39227ed","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-04-19T20:10:00.224612Z","iopub.execute_input":"2025-04-19T20:10:00.224891Z","iopub.status.idle":"2025-04-19T20:25:37.818817Z","shell.execute_reply.started":"2025-04-19T20:10:00.224869Z","shell.execute_reply":"2025-04-19T20:25:37.817996Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stderr","text":"I0000 00:00:1745093400.373898      31 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15513 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n","output_type":"stream"},{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\nEpoch 1/3\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1745093415.024030     113 service.cc:148] XLA service 0x79e6d004d2c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1745093415.024832     113 service.cc:156]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\nI0000 00:00:1745093416.453428     113 cuda_dnn.cc:529] Loaded cuDNN version 90300\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m   2/3125\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:54\u001b[0m 56ms/step - accuracy: 0.6094 - loss: 20.2341  ","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1745093420.704563     113 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m461s\u001b[0m 142ms/step - accuracy: 0.8750 - loss: 0.8578 - val_accuracy: 0.9395 - val_loss: 0.1617\nEpoch 2/3\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m255s\u001b[0m 81ms/step - accuracy: 0.9258 - loss: 0.1933 - val_accuracy: 0.9568 - val_loss: 0.1172\nEpoch 3/3\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 69ms/step - accuracy: 0.9372 - loss: 0.1630 - val_accuracy: 0.9655 - val_loss: 0.0860\nResNet baseline model trained and saved.\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"# Baseline Evaluation ","metadata":{"_uuid":"b622bb3b-48a9-4779-b7e9-09088f3450fe","_cell_guid":"9446d27a-fe5d-4701-a032-51e3cc541d14","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"baseline_model.compile(optimizer='adam',\n                     loss='binary_crossentropy',\n                     metrics=['accuracy'])","metadata":{"_uuid":"42d6171b-7feb-4e16-9a49-0c391fbaa05b","_cell_guid":"b13d1e36-8782-4190-9190-f1240034ad01","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-04-19T20:38:01.914200Z","iopub.execute_input":"2025-04-19T20:38:01.914516Z","iopub.status.idle":"2025-04-19T20:38:01.924477Z","shell.execute_reply.started":"2025-04-19T20:38:01.914489Z","shell.execute_reply":"2025-04-19T20:38:01.923844Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\n\nnum_batches = 20\nclean_accs = []\nfgsm_accs  = []\npgd_accs   = []\nloss_fn = tf.keras.losses.BinaryCrossentropy()\ntest_gen.reset()\n\nfor i in range(num_batches):\n    x_batch, y_batch = next(test_gen)\n    \n    # Clean accuracy\n    preds_clean = baseline_model(x_batch, training=False)\n    acc_clean = tf.reduce_mean(tf.cast(tf.equal(tf.round(preds_clean), y_batch), tf.float32)).numpy()\n    clean_accs.append(acc_clean)\n\n    # FGSM\n    x_adv_fgsm = fgsm_attack(baseline_model, tf.convert_to_tensor(x_batch), \n                            tf.convert_to_tensor(y_batch)).numpy()\n    preds_fgsm = baseline_model(x_adv_fgsm, training=False)\n    acc_fgsm = tf.reduce_mean(tf.cast(tf.equal(tf.round(preds_fgsm), y_batch), tf.float32)).numpy()\n    fgsm_accs.append(acc_fgsm)\n\n    # PGD\n    x_adv_pgd = pgd_attack(tf.convert_to_tensor(x_batch), y_batch, \n                          baseline_model, loss_fn).numpy()\n    preds_pgd = baseline_model(x_adv_pgd, training=False)\n    acc_pgd = tf.reduce_mean(tf.cast(tf.equal(tf.round(preds_pgd), y_batch), tf.float32)).numpy()\n    pgd_accs.append(acc_pgd)\n\nprint(f\"Clean Test Accuracy (avg over {num_batches} batches): {np.mean(clean_accs):.4f}\")\nprint(f\"FGSM Accuracy      (avg over {num_batches} batches): {np.mean(fgsm_accs):.4f}\")\nprint(f\"PGD Accuracy       (avg over {num_batches} batches): {np.mean(pgd_accs):.4f}\")","metadata":{"_uuid":"9f5aa8e5-f139-40fb-be0b-33f86c2e483a","_cell_guid":"c7bcfc43-c779-46c5-9462-e8c1b5e140be","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-04-19T20:38:06.918280Z","iopub.execute_input":"2025-04-19T20:38:06.919028Z","iopub.status.idle":"2025-04-19T20:39:44.744412Z","shell.execute_reply.started":"2025-04-19T20:38:06.919001Z","shell.execute_reply":"2025-04-19T20:39:44.743600Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","text":"Clean Test Accuracy (avg over 20 batches): 0.9250\nFGSM Accuracy      (avg over 20 batches): 0.1328\nPGD Accuracy       (avg over 20 batches): 0.1219\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"# Generate & Save Perturbed Training Data ","metadata":{"_uuid":"c6a7a26c-c495-4770-9cec-08e5648e68fa","_cell_guid":"1bd85cc7-43a1-4f22-9aa1-e2ae81bc2cc1","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"pert_dir = \"/kaggle/working/train_perturbed\"\nfor cls in ['REAL','FAKE']:\n    os.makedirs(os.path.join(pert_dir,cls), exist_ok=True)\n\n# Reload baseline\nbaseline_model = build_resnet()  # Changed to ResNet\nbaseline_model.load_weights(baseline_weights)\n\nno_shuffle = ImageDataGenerator(preprocessing_function=preprocess_input)\nno_shuffle = no_shuffle.flow_from_directory(\n    data_dir, target_size=(224,224), batch_size=32,\n    class_mode='binary', shuffle=False)\n\nloss_fn = tf.keras.losses.BinaryCrossentropy()\nnum_batches = len(no_shuffle)\n\nfor i in tqdm(range(num_batches)):\n    xb, yb = next(no_shuffle)\n    idx = no_shuffle.index_array[i*32:(i+1)*32]\n    paths = [no_shuffle.filepaths[k] for k in idx]\n    half = xb.shape[0]//2\n\n    x_f = fgsm_attack(baseline_model,\n                     tf.convert_to_tensor(xb[:half]),\n                     tf.convert_to_tensor(yb[:half])).numpy()\n    x_p = pgd_attack(tf.convert_to_tensor(xb[half:]),\n                     yb[half:], baseline_model, loss_fn).numpy()\n    x_comb = np.concatenate([x_f, x_p], axis=0)\n\n    for j, pth in enumerate(paths):\n        cls_name = 'REAL' if 'REAL' in pth else 'FAKE'\n        fn = os.path.basename(pth).replace('.jpg', f'_adv_{i}_{j}.jpg')\n        savep = os.path.join(pert_dir, cls_name, fn)\n        tf.keras.preprocessing.image.save_img(savep, x_comb[j])","metadata":{"_uuid":"6a3b535a-1469-4793-a576-1f794cf81461","_cell_guid":"7fb86f44-3131-4aea-b4f4-2448e23ff5bd","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-04-19T21:14:55.899961Z","iopub.execute_input":"2025-04-19T21:14:55.900699Z","iopub.status.idle":"2025-04-19T22:03:09.886712Z","shell.execute_reply.started":"2025-04-19T21:14:55.900673Z","shell.execute_reply":"2025-04-19T22:03:09.886069Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","text":"Found 100000 images belonging to 2 classes.\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 3125/3125 [47:36<00:00,  1.09it/s] \n","output_type":"stream"}],"execution_count":19},{"cell_type":"markdown","source":"# Adversarial Training & Saving ","metadata":{"_uuid":"fa4561c0-6673-4917-ad59-d9af480eb173","_cell_guid":"03a8c14f-9642-4c48-9485-90aaae85cb25","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"pert_gen = ImageDataGenerator(preprocessing_function=preprocess_input)\npert_gen = pert_gen.flow_from_directory(\n    pert_dir, target_size=(224,224), batch_size=32,\n    class_mode='binary', shuffle=True)\n\nadv_model = build_resnet()  \nadv_model.compile(optimizer='adam', loss='binary_crossentropy',\n                metrics=['accuracy'])\nadv_model.fit(pert_gen, epochs=3, validation_data=val_gen)\nadv_model.save('/kaggle/working/resnet_adv_model.h5')  \n\n","metadata":{"_uuid":"e0636986-f36b-4363-a61b-c20a2e902f9d","_cell_guid":"f2ed88e8-c218-4ac3-b727-29246e16c936","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-04-19T22:08:37.587084Z","iopub.execute_input":"2025-04-19T22:08:37.587373Z","iopub.status.idle":"2025-04-19T22:18:11.409241Z","shell.execute_reply.started":"2025-04-19T22:08:37.587352Z","shell.execute_reply":"2025-04-19T22:18:11.408275Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","text":"Found 100000 images belonging to 2 classes.\nEpoch 1/3\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 60ms/step - accuracy: 0.7165 - loss: 1.3159 - val_accuracy: 0.6726 - val_loss: 0.7969\nEpoch 2/3\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 58ms/step - accuracy: 0.7776 - loss: 0.4500 - val_accuracy: 0.6720 - val_loss: 0.8774\nEpoch 3/3\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 59ms/step - accuracy: 0.7998 - loss: 0.4136 - val_accuracy: 0.6399 - val_loss: 1.3010\n","output_type":"stream"}],"execution_count":22},{"cell_type":"markdown","source":"# Robustness Evaluation ","metadata":{}},{"cell_type":"code","source":"# FGSM evaluation\nx_t, y_t = next(test_gen)\nx_t_tensor = tf.convert_to_tensor(x_t)\ny_t_tensor = tf.convert_to_tensor(y_t)\nx_adv_fgsm = fgsm_attack(adv_model, x_t_tensor, y_t_tensor, epsilon=0.05).numpy()\nfgsm_loss, fgsm_acc = adv_model.evaluate(x_adv_fgsm, y_t, verbose=0)\nprint(f\"FGSM Accuracy on Robust Model: {fgsm_acc:.4f}\")\n\n# PGD evaluation\nx_p, y_p = next(test_gen) \nx_p_tensor = tf.convert_to_tensor(x_p)\ny_p_tensor = tf.convert_to_tensor(y_p)\n\nx_adv_pgd = pgd_attack(\n    x_p_tensor,\n    y_p_tensor,\n    adv_model,\n    loss_fn,\n    epsilon=0.03,\n    alpha=0.007,\n    iters=10\n).numpy()\n\npgd_loss, pgd_acc = adv_model.evaluate(x_adv_pgd, y_p, verbose=0)\nprint(f\"PGD Accuracy on Robust Model: {pgd_acc:.4f}\")","metadata":{"_uuid":"ebd1859e-3029-48a3-a9a7-f2959e943e3b","_cell_guid":"48a51785-a280-42ad-ad84-0d2d542109a8","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-04-19T22:31:38.592376Z","iopub.execute_input":"2025-04-19T22:31:38.592955Z","iopub.status.idle":"2025-04-19T22:31:40.627471Z","shell.execute_reply.started":"2025-04-19T22:31:38.592934Z","shell.execute_reply":"2025-04-19T22:31:40.626843Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","text":"FGSM Accuracy on Robust Model: 0.3750\nPGD Accuracy on Robust Model: 0.2812\n","output_type":"stream"}],"execution_count":26}]}