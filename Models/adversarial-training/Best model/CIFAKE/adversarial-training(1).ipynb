{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":5256696,"sourceType":"datasetVersion","datasetId":3041726},{"sourceId":339470,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":283878,"modelId":304720}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# ✅ Imports","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.applications.vgg19 import VGG19, preprocess_input\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Flatten, Dense, Dropout\nfrom tensorflow.keras.models import load_model\nimport numpy as np\nimport os\n","metadata":{"trusted":true},"outputs":[{"name":"stderr","text":"2025-04-15 18:32:22.139187: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1744741942.616141     339 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1744741942.756753     339 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"# ✅ Model Builder","metadata":{}},{"cell_type":"code","source":"def build_vgg19():\n    base = VGG19(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n    for layer in base.layers:\n        layer.trainable = False\n    x = Flatten()(base.output)\n    x = Dense(256, activation='relu')(x)\n    x = Dropout(0.5)(x)\n    out = Dense(1, activation='sigmoid')(x)\n    return Model(base.input, out)","metadata":{"trusted":true},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"# ✅ Data Generators","metadata":{}},{"cell_type":"code","source":"import shutil\nfrom sklearn.model_selection import train_test_split\n\nbase_dir = \"/kaggle/input/cifake-real-and-ai-generated-synthetic-images/train\"\nval_dir = \"/kaggle/working/validation\"\n\nfor label in ['REAL', 'FAKE']:\n    os.makedirs(os.path.join(val_dir, label), exist_ok=True)\n    files = os.listdir(os.path.join(base_dir, label))\n    train_files, val_files = train_test_split(files, test_size=0.2, random_state=42)\n\n    for fname in val_files:\n        src = os.path.join(base_dir, label, fname)\n        dst = os.path.join(val_dir, label, fname)\n        shutil.copyfile(src, dst)\n","metadata":{"trusted":true},"outputs":[],"execution_count":4},{"cell_type":"code","source":"train_gen = ImageDataGenerator(preprocessing_function=preprocess_input).flow_from_directory(\n    '/kaggle/input/cifake-real-and-ai-generated-synthetic-images/train',\n    target_size=(224, 224), batch_size=32, class_mode='binary', shuffle=True)\n\nval_gen = ImageDataGenerator(preprocessing_function=preprocess_input).flow_from_directory(\n    '/kaggle/working/validation',\n    target_size=(224, 224), batch_size=32, class_mode='binary', shuffle=False)\n\ntest_gen = ImageDataGenerator(preprocessing_function=preprocess_input).flow_from_directory(\n    '/kaggle/input/cifake-real-and-ai-generated-synthetic-images/test',\n    target_size=(224, 224), batch_size=32, class_mode='binary', shuffle=False)","metadata":{"trusted":true},"outputs":[{"name":"stdout","text":"Found 100000 images belonging to 2 classes.\nFound 20000 images belonging to 2 classes.\nFound 20000 images belonging to 2 classes.\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"# ✅ FGSM Attack Function and PGD Attack Function","metadata":{}},{"cell_type":"code","source":"@tf.function\ndef fgsm_attack(model, images, labels, epsilon=0.05):\n    with tf.GradientTape() as tape:\n        tape.watch(images)\n        predictions = model(images)\n        loss = tf.keras.losses.BinaryCrossentropy()(labels, predictions)\n    gradient = tape.gradient(loss, images)\n    signed_grad = tf.sign(gradient)\n    adv_images = images + epsilon * signed_grad\n    return tf.clip_by_value(adv_images, 0, 1)\n\n# ✅ PGD Attack Function\n@tf.function\ndef pgd_attack(x, y, model, loss_fn, epsilon=0.03, alpha=0.007, iters=10):\n    x_adv = tf.identity(x)\n\n    for i in range(iters):\n        with tf.GradientTape() as tape:\n            tape.watch(x_adv)\n            prediction = model(x_adv, training=False)\n            loss = loss_fn(y, prediction)\n\n        grad = tape.gradient(loss, x_adv)\n        signed_grad = tf.sign(grad)\n        x_adv = x_adv + alpha * signed_grad\n        x_adv = tf.clip_by_value(x_adv, x - epsilon, x + epsilon)\n        x_adv = tf.clip_by_value(x_adv, 0.0, 1.0)  # ensure valid pixel range\n\n    return x_adv\n","metadata":{"trusted":true},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"# ✅ Train and Save Baseline Model","metadata":{}},{"cell_type":"code","source":"# Paths to save model and weights\nweights_path_baseline = '/kaggle/working/vgg19_baseline_cifake.weights.h5'\nmodel_path_baseline   = '/kaggle/working/vgg19_baseline_cifake_model.h5'\n#Kaggle\nif os.path.exists('/kaggle/input/vgg19_baseline_cifake/tensorflow2/default/1/vgg19_baseline_cifake_model.h5'):\n    print(\"Loading saved model...\")\n    baseline_model = load_model('/kaggle/input/vgg19_baseline_cifake/tensorflow2/default/1/vgg19_baseline_cifake_model.h5')\n#Colab\n# if os.path.exists(model_path_baseline):\n#     print(\"Loading saved model...\")\n#     baseline_model = load_model(model_path_baseline)\nelse:\n    print(\"Training baseline model...\")\n    baseline_model = build_vgg19()\n    baseline_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n    baseline_model.fit(train_gen, epochs=3, validation_data=val_gen)\n    baseline_model.save_weights(weights_path_baseline)\n    baseline_model.save(model_path_baseline)\n    print(\"Baseline model trained and saved.\")\n\nprint(\"\\nEvaluating Baseline Model on Clean Test Set:\")\nbaseline_clean_acc = baseline_model.evaluate(test_gen)\nprint(\"Baseline Clean Accuracy:\", baseline_clean_acc)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T14:23:59.637526Z","iopub.execute_input":"2025-04-15T14:23:59.637779Z","iopub.status.idle":"2025-04-15T14:26:55.280318Z","shell.execute_reply.started":"2025-04-15T14:23:59.637757Z","shell.execute_reply":"2025-04-15T14:26:55.279689Z"}},"outputs":[{"name":"stdout","text":"Loading saved model...\n","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1744727042.531207      31 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\nI0000 00:00:1744727042.531875      31 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13942 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n","output_type":"stream"},{"name":"stdout","text":"\nEvaluating Baseline Model on Clean Test Set:\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1744727047.967304     113 service.cc:148] XLA service 0x79de8c00c100 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1744727047.969142     113 service.cc:156]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\nI0000 00:00:1744727047.969163     113 service.cc:156]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5\nI0000 00:00:1744727048.219918     113 cuda_dnn.cc:529] Loaded cuDNN version 90300\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m  1/625\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:11:37\u001b[0m 13s/step - accuracy: 0.9375 - loss: 0.3287","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1744727059.586375     113 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 249ms/step - accuracy: 0.8809 - loss: 0.2490\nBaseline Clean Accuracy: [0.20891635119915009, 0.913349986076355]\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"# ✅ FGSM Vulnerability Evaluation","metadata":{}},{"cell_type":"code","source":"x_test_sample, y_test_sample = next(test_gen)\nx_test_tensor = tf.convert_to_tensor(x_test_sample, dtype=tf.float32)\ny_test_tensor = tf.convert_to_tensor(y_test_sample, dtype=tf.float32)\n\nx_fgsm_test = fgsm_attack(baseline_model, x_test_tensor, y_test_tensor)\nprint(\"\\nEvaluating Baseline Model on FGSM-Adversarial Examples:\")\nbaseline_fgsm_acc = baseline_model.evaluate(x_fgsm_test, y_test_sample)\nprint(\"Baseline Accuracy on FGSM-Adversarial:\", baseline_fgsm_acc)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T14:26:55.281015Z","iopub.execute_input":"2025-04-15T14:26:55.281274Z","iopub.status.idle":"2025-04-15T14:27:04.791783Z","shell.execute_reply.started":"2025-04-15T14:26:55.281255Z","shell.execute_reply":"2025-04-15T14:27:04.791159Z"}},"outputs":[{"name":"stdout","text":"\nEvaluating Baseline Model on FGSM-Adversarial Examples:\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 288ms/step - accuracy: 0.1250 - loss: 1.1523\nBaseline Accuracy on FGSM-Adversarial: [1.152273416519165, 0.125]\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"# Generate and Save Perturbed Data (FGSM + PGD)","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nimport os\nfrom tqdm import tqdm\n\n# Directories\nbase_train_dir = \"/kaggle/input/cifake-real-and-ai-generated-synthetic-images/train\"\nperturbed_dir = \"/kaggle/working/train_perturbed_only\"  # All perturbed, no clean data\nweights_path_baseline = \"/kaggle/input/vgg19_baseline_cifake/tensorflow2/default/1/vgg19_baseline_cifake.weights.h5\"\n\n# Create directories\nos.makedirs(os.path.join(perturbed_dir, 'REAL'), exist_ok=True)\nos.makedirs(os.path.join(perturbed_dir, 'FAKE'), exist_ok=True)\n\n# Load baseline model (for generating perturbations)\nbaseline_model = build_vgg19()\nbaseline_model.load_weights(weights_path_baseline)  # Pretrained weights\n\n# Data generator (no shuffling for consistent file mapping)\ntrain_gen = ImageDataGenerator(preprocessing_function=preprocess_input).flow_from_directory(\n    base_train_dir,\n    target_size=(224, 224),\n    batch_size=32,\n    class_mode='binary',\n    shuffle=False  # Critical for matching files to paths\n)\n\n# Attack parameters\nepsilon_fgsm = 0.05\nepsilon_pgd = 0.03\nalpha_pgd = 0.007\niters_pgd = 10\nloss_fn = tf.keras.losses.BinaryCrossentropy()\n\n# Generate and save perturbed data\nnum_batches = len(train_gen)\n\nfor i in tqdm(range(num_batches)):\n    x_batch, y_batch = next(train_gen)\n    \n    # Get indices and paths for this batch\n    batch_indices = train_gen.index_array[i*32 : (i+1)*32]\n    paths = [train_gen.filepaths[idx] for idx in batch_indices]\n\n    # Split batch: 50% FGSM, 50% PGD\n    split = len(x_batch) // 2\n\n    # Generate FGSM samples\n    x_fgsm = fgsm_attack(\n        baseline_model, \n        tf.convert_to_tensor(x_batch[:split]), \n        tf.convert_to_tensor(y_batch[:split]), \n        epsilon_fgsm\n    ).numpy()\n\n    # Generate PGD samples\n    x_pgd = pgd_attack(\n        tf.convert_to_tensor(x_batch[split:]), \n        y_batch[split:], \n        baseline_model, \n        loss_fn,\n        epsilon=epsilon_pgd, \n        alpha=alpha_pgd, \n        iters=iters_pgd\n    ).numpy()\n\n    # Combine and save\n    x_perturbed = np.concatenate([x_fgsm, x_pgd], axis=0)\n\n    # Save images\n    for j, path in enumerate(paths):\n        class_name = 'REAL' if 'REAL' in path else 'FAKE'\n        filename = os.path.basename(path).replace('.jpg', f'_perturbed_{i}_{j}.jpg')\n        save_path = os.path.join(perturbed_dir, class_name, filename)\n        tf.keras.preprocessing.image.save_img(save_path, x_perturbed[j])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T14:28:17.783200Z","iopub.execute_input":"2025-04-15T14:28:17.783769Z","iopub.status.idle":"2025-04-15T16:43:30.293547Z","shell.execute_reply.started":"2025-04-15T14:28:17.783745Z","shell.execute_reply":"2025-04-15T16:43:30.292772Z"}},"outputs":[{"name":"stdout","text":"Found 100000 images belonging to 2 classes.\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 3125/3125 [2:14:12<00:00,  2.58s/it]  \n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"# Train on Perturbed Data","metadata":{}},{"cell_type":"code","source":"perturbed_gen = ImageDataGenerator(preprocessing_function=preprocess_input).flow_from_directory(\n    \"/kaggle/working/train_perturbed_only\",  # Directory with 100% perturbed data\n    target_size=(224, 224),\n    batch_size=32,\n    class_mode='binary',\n    shuffle=True\n)\n\n# Initialize model (same architecture as baseline)\nadv_model = build_vgg19()\nadv_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n\n# Train exclusively on adversarial data\nadv_model.fit(perturbed_gen, epochs=3, validation_data=val_gen)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T18:39:29.166012Z","iopub.execute_input":"2025-04-15T18:39:29.166736Z","iopub.status.idle":"2025-04-15T19:25:19.361492Z","shell.execute_reply.started":"2025-04-15T18:39:29.166709Z","shell.execute_reply":"2025-04-15T19:25:19.360660Z"}},"outputs":[{"name":"stdout","text":"Found 100000 images belonging to 2 classes.\n","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1744742373.180338     339 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\nI0000 00:00:1744742373.181059     339 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13942 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/3\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1744742379.193533     401 service.cc:148] XLA service 0x7f47b400e220 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1744742379.199739     401 service.cc:156]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\nI0000 00:00:1744742379.199771     401 service.cc:156]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5\nI0000 00:00:1744742379.749710     401 cuda_dnn.cc:529] Loaded cuDNN version 90300\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m   1/3125\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m13:44:42\u001b[0m 16s/step - accuracy: 0.5625 - loss: 5.8884","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1744742391.808150     401 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m910s\u001b[0m 286ms/step - accuracy: 0.7026 - loss: 1.5068 - val_accuracy: 0.6962 - val_loss: 0.7808\nEpoch 2/3\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m915s\u001b[0m 293ms/step - accuracy: 0.7626 - loss: 0.4895 - val_accuracy: 0.7009 - val_loss: 0.7069\nEpoch 3/3\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m918s\u001b[0m 294ms/step - accuracy: 0.7726 - loss: 0.4654 - val_accuracy: 0.6479 - val_loss: 1.4056\n","output_type":"stream"},{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7f4882f79610>"},"metadata":{}}],"execution_count":8},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"# Saving the Model","metadata":{}},{"cell_type":"code","source":"    weights_path_adv = '/kaggle/working/vgg19_adv_cifake.weights.h5'\n    model_path_adv   = '/kaggle/working/vgg19_adv_cifake_model.h5'\n    \n    adv_model.save_weights(weights_path_adv)\n    adv_model.save(model_path_adv)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T17:29:20.705355Z","iopub.execute_input":"2025-04-15T17:29:20.705535Z","iopub.status.idle":"2025-04-15T17:29:21.253898Z","shell.execute_reply.started":"2025-04-15T17:29:20.705515Z","shell.execute_reply":"2025-04-15T17:29:21.253289Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"# Evaluate Robustness","metadata":{}},{"cell_type":"code","source":"# Evaluate on clean test data (optional)\nclean_loss, clean_acc = adv_model.evaluate(test_gen, verbose=0)\nprint(f\"Clean Test Accuracy: {clean_acc:.4f}\")\n\n# Evaluate on FGSM-attacked test data\nx_test, y_test = next(test_gen)\nx_fgsm_test = fgsm_attack(adv_model, tf.convert_to_tensor(x_test), tf.convert_to_tensor(y_test), 0.05)\nfgsm_loss, fgsm_acc = adv_model.evaluate(x_fgsm_test, y_test, verbose=0)\nprint(f\"FGSM Test Accuracy: {fgsm_acc:.4f} (Baseline was ~12.5%)\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T19:59:32.692297Z","iopub.execute_input":"2025-04-15T19:59:32.692662Z","iopub.status.idle":"2025-04-15T20:02:06.099731Z","shell.execute_reply.started":"2025-04-15T19:59:32.692636Z","shell.execute_reply":"2025-04-15T20:02:06.099034Z"}},"outputs":[{"name":"stdout","text":"Clean Test Accuracy: 0.6515\nFGSM Test Accuracy: 0.7500 (Baseline was ~12.5%)\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"import shutil\n\n# Example: zip the 'my_folder' inside /kaggle/working\nshutil.make_archive('/kaggle/working/train_perturbed_only', 'zip', '/kaggle/working')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T17:45:04.107995Z","iopub.execute_input":"2025-04-15T17:45:04.108727Z","iopub.status.idle":"2025-04-15T17:45:50.434121Z","shell.execute_reply.started":"2025-04-15T17:45:04.108704Z","shell.execute_reply":"2025-04-15T17:45:50.433450Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working/train_perturbed_only.zip'"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"# Load all test images in memory\nx_test_all = []\ny_test_all = []\n\nfor i in range(len(test_gen)):\n    x_batch, y_batch = next(test_gen)\n    x_test_all.append(x_batch)\n    y_test_all.append(y_batch)\n\nx_test_all = np.concatenate(x_test_all, axis=0)\ny_test_all = np.concatenate(y_test_all, axis=0)\n\n# FGSM attack on the full test set\nx_test_tensor = tf.convert_to_tensor(x_test_all, dtype=tf.float32)\ny_test_tensor = tf.convert_to_tensor(y_test_all, dtype=tf.float32)\n\nx_fgsm_all = fgsm_attack(adv_model, x_test_tensor, y_test_tensor, epsilon=epsilon_fgsm).numpy()\n\n# Evaluate on perturbed FGSM test images\nfgsm_loss, fgsm_acc = adv_model.evaluate(x_fgsm_all, y_test_all, verbose=0)\nprint(f\"FGSM Test Accuracy: {fgsm_acc:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T20:02:06.100896Z","iopub.execute_input":"2025-04-15T20:02:06.101152Z","execution_failed":"2025-04-15T20:03:10.201Z"}},"outputs":[],"execution_count":null}]}