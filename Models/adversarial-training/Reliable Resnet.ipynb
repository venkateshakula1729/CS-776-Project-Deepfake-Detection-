{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":5256696,"sourceType":"datasetVersion","datasetId":3041726}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nimport torch.backends.cudnn as cudnn\nfrom torch.autograd import *\nimport torchvision\nimport torchvision.transforms as transforms\nimport os\nimport argparse\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn.metrics import confusion_matrix\nimport seaborn as sns\n\n# Set device\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nlr = 0.01","metadata":{"_uuid":"e62ef005-1ee3-43bf-a429-3f5a0b6d8ecf","_cell_guid":"b897d9ac-9dfa-44f9-9f03-f82ea2575aed","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-04-18T19:24:52.169009Z","iopub.execute_input":"2025-04-18T19:24:52.169298Z","iopub.status.idle":"2025-04-18T19:25:00.625923Z","shell.execute_reply.started":"2025-04-18T19:24:52.169273Z","shell.execute_reply":"2025-04-18T19:25:00.625353Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\nclass BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, in_planes, planes, stride=1):\n        super(BasicBlock, self).__init__()\n        self.conv1 = nn.Conv2d(\n            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n                               stride=1, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n\n        self.shortcut = nn.Sequential()\n        if stride != 1 or in_planes != self.expansion*planes:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(in_planes, self.expansion*planes,\n                          kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(self.expansion*planes)\n            )\n\n    def forward(self, x):\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = self.bn2(self.conv2(out))\n        out += self.shortcut(x)\n        out = F.relu(out)\n        return out\n\n\nclass Bottleneck(nn.Module):\n    expansion = 4\n\n    def __init__(self, in_planes, planes, stride=1):\n        super(Bottleneck, self).__init__()\n        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n                               stride=stride, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.conv3 = nn.Conv2d(planes, self.expansion *\n                               planes, kernel_size=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n\n        self.shortcut = nn.Sequential()\n        if stride != 1 or in_planes != self.expansion*planes:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(in_planes, self.expansion*planes,\n                          kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(self.expansion*planes)\n            )\n\n    def forward(self, x):\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = F.relu(self.bn2(self.conv2(out)))\n        out = self.bn3(self.conv3(out))\n        out += self.shortcut(x)\n        out = F.relu(out)\n        return out\n\n\nclass ResNet(nn.Module):\n    def __init__(self, block, num_blocks, num_classes=2):\n        super(ResNet, self).__init__()\n        self.in_planes = 64\n\n        self.conv1 = nn.Conv2d(3, 64, kernel_size=3,\n                               stride=1, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n        self.linear = nn.Linear(512*block.expansion, num_classes)\n\n    def _make_layer(self, block, planes, num_blocks, stride):\n        strides = [stride] + [1]*(num_blocks-1)\n        layers = []\n        for stride in strides:\n            layers.append(block(self.in_planes, planes, stride))\n            self.in_planes = planes * block.expansion\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = self.layer1(out)\n        out = self.layer2(out)\n        out = self.layer3(out)\n        out = self.layer4(out)\n        out = F.avg_pool2d(out, 4)\n        out = out.view(out.size(0), -1)\n        out = self.linear(out)\n        return out\n\n\ndef ResNet18(num_classes=2):\n    return ResNet(BasicBlock, [2, 2, 2, 2])\n\n\ndef ResNet34():\n    return ResNet(BasicBlock, [3, 4, 6, 3])\n\n\ndef ResNet50():\n    return ResNet(Bottleneck, [3, 4, 6, 3])\n\ndef ResNet101():\n    return ResNet(Bottleneck, [3, 4, 23, 3])\n\n\ndef ResNet152():\n    return ResNet(Bottleneck, [3, 8, 36, 3])\n\n\ndef test():\n    net = ResNet18()\n    y = net(torch.randn(1, 3, 32, 32))\n    print(y.size())","metadata":{"_uuid":"caa68ae3-f261-44a7-9eff-16be5eebd8b5","_cell_guid":"5737362d-d76b-4560-b5c9-a69b26bd401c","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-04-18T19:25:22.673126Z","iopub.execute_input":"2025-04-18T19:25:22.673684Z","iopub.status.idle":"2025-04-18T19:25:22.689050Z","shell.execute_reply.started":"2025-04-18T19:25:22.673658Z","shell.execute_reply":"2025-04-18T19:25:22.688473Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"\n# Data Preparation\nprint('==> Preparing CIFAKE data..')\ntransform_train = transforms.Compose([\n    transforms.RandomCrop(32, padding=4),\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n])\n\ntransform_test = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n])\n\n# Custom dataset class for CIFAKE\nclass CIFAKE(torchvision.datasets.ImageFolder):\n    def __init__(self, root, transform=None):\n        super(CIFAKE, self).__init__(root, transform=transform)\n        # Map class names to indices\n        self.class_to_idx = {'REAL': 0, 'FAKE': 1}\n        self.idx_to_class = {0: 'REAL', 1: 'FAKE'}\n\n# Load CIFAKE dataset\ntrain_path = '/kaggle/input/cifake-real-and-ai-generated-synthetic-images/train'\ntest_path = '/kaggle/input/cifake-real-and-ai-generated-synthetic-images/test'\n\ntrainset = CIFAKE(root=train_path, transform=transform_train)\ntestset = CIFAKE(root=test_path, transform=transform_test)\n\ntrainloader = torch.utils.data.DataLoader(\n    trainset, batch_size=128, shuffle=True, num_workers=2)\n\ntestloader = torch.utils.data.DataLoader(\n    testset, batch_size=100, shuffle=False, num_workers=2)","metadata":{"_uuid":"1d774f5b-cc5a-4adf-b49f-c6149d1b58d3","_cell_guid":"f163942e-f0a2-4488-a29c-7f2f3dbbd679","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-04-18T19:25:27.974054Z","iopub.execute_input":"2025-04-18T19:25:27.974746Z","iopub.status.idle":"2025-04-18T19:28:13.099095Z","shell.execute_reply.started":"2025-04-18T19:25:27.974719Z","shell.execute_reply":"2025-04-18T19:28:13.098301Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","text":"==> Preparing CIFAKE data..\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# Add these imports at the top of your file\nimport time\nfrom tqdm import tqdm\n\n# Model\nprint('==> Building model..')\nnet = ResNet18(num_classes=2)  # 2 classes for REAL and FAKE\nnet = net.to(device)\nif device == 'cuda':\n    net = torch.nn.DataParallel(net)\n    cudnn.benchmark = True\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(net.parameters(), lr=lr, momentum=0.9, weight_decay=5e-4)\nscheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\n\n# Training and Test Functions with progress bars\ndef train(epoch, net):\n    net.train()\n    train_loss = 0\n    correct = 0\n    total = 0\n    start_time = time.time()\n    \n    with tqdm(trainloader, unit=\"batch\") as tepoch:\n        tepoch.set_description(f\"Epoch {epoch+1}\")\n        for batch_idx, (inputs, targets) in enumerate(tepoch):\n            inputs, targets = inputs.to(device), targets.to(device)\n            optimizer.zero_grad()\n            outputs = net(inputs)\n            loss = criterion(outputs, targets)\n            loss.backward()\n            optimizer.step()\n\n            train_loss += loss.item()\n            _, predicted = outputs.max(1)\n            total += targets.size(0)\n            correct += predicted.eq(targets).sum().item()\n            \n            # Update progress bar\n            tepoch.set_postfix(loss=loss.item(), accuracy=100.*correct/total)\n    \n    epoch_time = time.time() - start_time\n    print(f\"Epoch {epoch+1} training time: {epoch_time:.2f} seconds\")\n    return train_loss/len(trainloader)\n\ndef test(epoch, net):\n    global acc\n    net.eval()\n    test_loss = 0\n    correct = 0\n    total = 0\n    start_time = time.time()\n    \n    with torch.no_grad():\n        with tqdm(testloader, unit=\"batch\") as tepoch:\n            tepoch.set_description(f\"Test {epoch+1}\")\n            for batch_idx, (inputs, targets) in enumerate(tepoch):\n                inputs, targets = inputs.to(device), targets.to(device)\n                outputs = net(inputs)\n                loss = criterion(outputs, targets)\n\n                test_loss += loss.item()\n                _, predicted = outputs.max(1)\n                total += targets.size(0)\n                correct += predicted.eq(targets).sum().item()\n                \n                # Update progress bar\n                tepoch.set_postfix(loss=loss.item(), accuracy=100.*correct/total)\n    \n    test_time = time.time() - start_time\n    print(f\"Test {epoch+1} time: {test_time:.2f} seconds\")\n    acc = 100 * correct / total\n    return test_loss/len(testloader)\n\n# Training Loop\ntrain_losses = []\ntest_losses = []\nepochs = 5\n\ntotal_start_time = time.time()\nfor epoch in range(epochs):\n    train_losses.append(train(epoch, net))\n    test_losses.append(test(epoch, net))\n    scheduler.step()\n\ntotal_time = time.time() - total_start_time\nprint(f'Total training time: {total_time:.2f} seconds')\nprint('Accuracy of the network on the test images: %d %%' % (acc))\n\n# Plot training curves\nplt.figure(figsize=(10, 5))\nplt.plot(np.arange(1, epochs+1), train_losses, label='Train Loss')\nplt.plot(np.arange(1, epochs+1), test_losses, label='Test Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.title('Training and Test Loss Curves')\nplt.savefig('training_curves.png')\nplt.show()\n\n# Confusion Matrix\ndef plot_confusion_matrix(model, data_loader, device):\n    model.eval()\n    all_preds = []\n    all_targets = []\n    start_time = time.time()\n    \n    with torch.no_grad():\n        with tqdm(data_loader, unit=\"batch\") as tepoch:\n            tepoch.set_description(\"Creating confusion matrix\")\n            for images, labels in data_loader:\n                images = images.to(device)\n                labels = labels.to(device)\n                \n                outputs = model(images)\n                _, preds = torch.max(outputs, 1)\n                \n                all_preds.extend(preds.cpu().numpy())\n                all_targets.extend(labels.cpu().numpy())\n    \n    cm_time = time.time() - start_time\n    print(f\"Confusion matrix generation time: {cm_time:.2f} seconds\")\n    \n    cm = confusion_matrix(all_targets, all_preds)\n    \n    plt.figure(figsize=(8, 6))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n                xticklabels=['REAL', 'FAKE'], \n                yticklabels=['REAL', 'FAKE'])\n    plt.xlabel('Predicted')\n    plt.ylabel('True')\n    plt.title('Confusion Matrix')\n    plt.savefig('confusion_matrix.png')\n    plt.show()\n\nplot_confusion_matrix(net, testloader, device)\n\n# Save the model\nprint(\"==> Saving model...\")\nmodel_save_time = time.time()\ntorch.save({\n    'model_state_dict': net.state_dict(),\n    'optimizer_state_dict': optimizer.state_dict(),\n    'scheduler_state_dict': scheduler.state_dict(),\n}, 'resnet18_model.pth')\nprint(f\"Model saved in {time.time() - model_save_time:.2f} seconds\")","metadata":{"_uuid":"3313c477-cdbb-4a51-97d0-9238d327e7b6","_cell_guid":"29531e5c-43b9-4c81-baad-3cfe1b4b0f23","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-04-18T19:28:21.127732Z","iopub.execute_input":"2025-04-18T19:28:21.128004Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","text":"==> Building model..\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1: 100%|██████████| 782/782 [06:33<00:00,  1.99batch/s, accuracy=89, loss=0.0626]  \n","output_type":"stream"},{"name":"stdout","text":"Epoch 1 training time: 393.07 seconds\n","output_type":"stream"},{"name":"stderr","text":"Test 1: 100%|██████████| 200/200 [01:18<00:00,  2.55batch/s, accuracy=91.7, loss=0.163] \n","output_type":"stream"},{"name":"stdout","text":"Test 1 time: 78.49 seconds\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  38%|███▊      | 299/782 [00:30<00:51,  9.38batch/s, accuracy=92.8, loss=0.167] ","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"torch.save({\n    'epoch': epochs,\n    'model_state_dict': net.state_dict(),\n    'optimizer_state_dict': optimizer.state_dict(),\n    'scheduler_state_dict': scheduler.state_dict(),\n    'train_losses': train_losses,\n    'test_losses': test_losses,\n}, 'resnet18_final.pth')\nprint(\"Final model saved as resnet18_final.pth\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torchsummary import summary\n\nsummary(net, input_size=(3, 32, 32))  ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T19:52:19.689845Z","iopub.execute_input":"2025-04-18T19:52:19.690704Z","iopub.status.idle":"2025-04-18T19:52:19.708794Z","shell.execute_reply.started":"2025-04-18T19:52:19.690676Z","shell.execute_reply":"2025-04-18T19:52:19.707907Z"}},"outputs":[{"name":"stdout","text":"----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n            Conv2d-1           [-1, 64, 32, 32]           1,728\n       BatchNorm2d-2           [-1, 64, 32, 32]             128\n            Conv2d-3           [-1, 64, 32, 32]          36,864\n       BatchNorm2d-4           [-1, 64, 32, 32]             128\n            Conv2d-5           [-1, 64, 32, 32]          36,864\n       BatchNorm2d-6           [-1, 64, 32, 32]             128\n        BasicBlock-7           [-1, 64, 32, 32]               0\n            Conv2d-8           [-1, 64, 32, 32]          36,864\n       BatchNorm2d-9           [-1, 64, 32, 32]             128\n           Conv2d-10           [-1, 64, 32, 32]          36,864\n      BatchNorm2d-11           [-1, 64, 32, 32]             128\n       BasicBlock-12           [-1, 64, 32, 32]               0\n           Conv2d-13          [-1, 128, 16, 16]          73,728\n      BatchNorm2d-14          [-1, 128, 16, 16]             256\n           Conv2d-15          [-1, 128, 16, 16]         147,456\n      BatchNorm2d-16          [-1, 128, 16, 16]             256\n           Conv2d-17          [-1, 128, 16, 16]           8,192\n      BatchNorm2d-18          [-1, 128, 16, 16]             256\n       BasicBlock-19          [-1, 128, 16, 16]               0\n           Conv2d-20          [-1, 128, 16, 16]         147,456\n      BatchNorm2d-21          [-1, 128, 16, 16]             256\n           Conv2d-22          [-1, 128, 16, 16]         147,456\n      BatchNorm2d-23          [-1, 128, 16, 16]             256\n       BasicBlock-24          [-1, 128, 16, 16]               0\n           Conv2d-25            [-1, 256, 8, 8]         294,912\n      BatchNorm2d-26            [-1, 256, 8, 8]             512\n           Conv2d-27            [-1, 256, 8, 8]         589,824\n      BatchNorm2d-28            [-1, 256, 8, 8]             512\n           Conv2d-29            [-1, 256, 8, 8]          32,768\n      BatchNorm2d-30            [-1, 256, 8, 8]             512\n       BasicBlock-31            [-1, 256, 8, 8]               0\n           Conv2d-32            [-1, 256, 8, 8]         589,824\n      BatchNorm2d-33            [-1, 256, 8, 8]             512\n           Conv2d-34            [-1, 256, 8, 8]         589,824\n      BatchNorm2d-35            [-1, 256, 8, 8]             512\n       BasicBlock-36            [-1, 256, 8, 8]               0\n           Conv2d-37            [-1, 512, 4, 4]       1,179,648\n      BatchNorm2d-38            [-1, 512, 4, 4]           1,024\n           Conv2d-39            [-1, 512, 4, 4]       2,359,296\n      BatchNorm2d-40            [-1, 512, 4, 4]           1,024\n           Conv2d-41            [-1, 512, 4, 4]         131,072\n      BatchNorm2d-42            [-1, 512, 4, 4]           1,024\n       BasicBlock-43            [-1, 512, 4, 4]               0\n           Conv2d-44            [-1, 512, 4, 4]       2,359,296\n      BatchNorm2d-45            [-1, 512, 4, 4]           1,024\n           Conv2d-46            [-1, 512, 4, 4]       2,359,296\n      BatchNorm2d-47            [-1, 512, 4, 4]           1,024\n       BasicBlock-48            [-1, 512, 4, 4]               0\n           Linear-49                    [-1, 2]           1,026\n           ResNet-50                    [-1, 2]               0\n================================================================\nTotal params: 11,169,858\nTrainable params: 11,169,858\nNon-trainable params: 0\n----------------------------------------------------------------\nInput size (MB): 0.01\nForward/backward pass size (MB): 11.25\nParams size (MB): 42.61\nEstimated Total Size (MB): 53.87\n----------------------------------------------------------------\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"from tqdm import tqdm\nimport time\n\n# Modify the FGSM attack function to show progress (if used in loops)\ndef FGSM(net, x, y, eps):\n    x_ = Variable(x.data, requires_grad=True)\n    h_ = net(x_)\n    cost = criterion(h_, y)\n    net.zero_grad()\n    cost.backward()\n\n    pert = eps * x_.grad.detach().sign()\n    x_adv = x_ + pert\n\n    h_adv = net(x_adv)\n    _, y_adv = torch.max(h_adv.data, 1)\n    return x_adv, h_adv, y_adv, pert\n\nepochs = 3\n\noptimizer_adv = optim.SGD(net_adv.parameters(), lr=lr, momentum=0.9, weight_decay=5e-4)\nscheduler_adv = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer_adv, T_max=200)\n\n# Adversarial Training with FGSM - add progress bar\ndef train_adv(epoch, net):\n    net.train()\n    train_loss = 0\n    correct = 0\n    total = 0\n    eps = 8/255\n    start_time = time.time()\n    \n    with tqdm(trainloader, unit=\"batch\") as tepoch:\n        tepoch.set_description(f\"Adv Epoch {epoch+1}\")\n        for batch_idx, (inputs, targets) in enumerate(tepoch):\n            inputs, targets = inputs.to(device), targets.to(device)\n\n            inputs_ = Variable(inputs.data, requires_grad=True)\n            h_ = net(inputs_)\n            cost = criterion(h_, targets)\n            net.zero_grad()\n            cost.backward()\n\n            pert = eps * inputs_.grad.detach().sign()\n            x_adv = inputs_ + pert\n\n            optimizer_adv.zero_grad()\n            outputs = net_adv(x_adv)\n            loss = criterion(outputs, targets)\n            loss.backward()\n            optimizer_adv.step()\n\n            train_loss += loss.item()\n            _, predicted = outputs.max(1)\n            total += targets.size(0)\n            correct += predicted.eq(targets).sum().item()\n            \n            # Update progress bar\n            tepoch.set_postfix(loss=loss.item(), accuracy=100.*correct/total)\n    \n    epoch_time = time.time() - start_time\n    print(f\"Adv Epoch {epoch+1} time: {epoch_time:.2f} seconds\")\n    return train_loss/len(trainloader)\n\n# Train adversarial model with progress\ntrain_losses_adv = []\ntest_losses_adv = []\ntotal_start_time = time.time()\n\nfor epoch in range(epochs):\n    train_losses_adv.append(train_adv(epoch, net))\n    test_losses_adv.append(test(epoch, net_adv))\n    scheduler_adv.step()\n\ntotal_time = time.time() - total_start_time\nprint(f'Total adversarial training time: {total_time:.2f} seconds')\nprint('Accuracy of adversarially-trained network: %d %%' % (acc))\n\n# Evaluate against FGSM attacks with progress\ndef test_adv(net, net_adv, eps):\n    net.train()\n    net_adv.eval()\n    correct = 0\n    total = 0\n    start_time = time.time()\n    \n    with tqdm(testloader, unit=\"batch\") as tepoch:\n        tepoch.set_description(f\"FGSM Test (ε={eps:.4f})\")\n        for batch_idx, (inputs, targets) in enumerate(tepoch):\n            inputs, targets = inputs.to(device), targets.to(device)\n            x_adv, _, _, _ = FGSM(net, inputs, targets, eps)\n            \n            with torch.no_grad():\n                outputs = net_adv(x_adv)\n                _, predicted = outputs.max(1)\n                total += targets.size(0)\n                correct += predicted.eq(targets).sum().item()\n                \n            # Update progress bar\n            tepoch.set_postfix(accuracy=100.*correct/total)\n    \n    test_time = time.time() - start_time\n    print(f\"FGSM test (ε={eps:.4f}) time: {test_time:.2f} seconds\")\n    return 100 * correct / total\n\nprint(\"Evaluating against FGSM attacks:\")\nfor eps in [4/255, 8/255, 12/255]:\n    accuracy = test_adv(net, net_adv, eps)\n    print(f\"Epsilon: {eps:.4f}, Accuracy: {accuracy:.2f}%\")","metadata":{"_uuid":"b308c691-8536-4415-a071-3e67e197475f","_cell_guid":"a004610a-5eaf-4193-b6b7-532f0a73f1ad","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-04-16T16:25:39.462589Z","iopub.execute_input":"2025-04-16T16:25:39.462906Z","iopub.status.idle":"2025-04-16T17:16:39.625062Z","shell.execute_reply.started":"2025-04-16T16:25:39.462884Z","shell.execute_reply":"2025-04-16T17:16:39.624218Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nepochs = 5\n\n\n# PGD Attack Function with progress\ndef PGD(net, x, y, alpha, epsilon, iter):\n    delta = torch.zeros_like(x, requires_grad=True)\n    for i in range(iter):\n        loss = criterion(net(x + delta), y)\n        loss.backward()\n        delta.data = (delta + x.shape[0]*alpha*delta.grad.data).clamp(-epsilon, epsilon)\n        delta.grad.zero_()\n    pert = delta.detach()\n    x_adv = x + pert\n    h_adv = net(x_adv)\n    _, y_adv = torch.max(h_adv.data, 1)\n    return x_adv, h_adv, y_adv, pert\n\n# Adversarial Training with PGD - add progress bar\ndef train_pgd(epoch, net, alpha, epsilon, iter):\n    net.train()\n    train_loss = 0\n    correct = 0\n    total = 0\n    start_time = time.time()\n    \n    with tqdm(trainloader, unit=\"batch\") as tepoch:\n        tepoch.set_description(f\"PGD Epoch {epoch+1}\")\n        for batch_idx, (inputs, targets) in enumerate(tepoch):\n            inputs, targets = inputs.to(device), targets.to(device)\n            x_adv, _, _, _ = PGD(net, inputs, targets, alpha, epsilon, iter)\n\n            optimizer_pgd.zero_grad()\n            outputs = net_pgd(x_adv)\n            loss = criterion(outputs, targets)\n            loss.backward()\n            optimizer_pgd.step()\n\n            train_loss += loss.item()\n            _, predicted = outputs.max(1)\n            total += targets.size(0)\n            correct += predicted.eq(targets).sum().item()\n            \n            # Update progress bar\n            tepoch.set_postfix(loss=loss.item(), accuracy=100.*correct/total)\n    \n    epoch_time = time.time() - start_time\n    print(f\"PGD Epoch {epoch+1} time: {epoch_time:.2f} seconds\")\n    return train_loss/len(trainloader)\n\n# Adversarial Training with PGD\nprint('==> Building PGD adversarial model..')\nnet_pgd = ResNet18(num_classes=2).to(device)\nif device == 'cuda':\n    net_pgd = torch.nn.DataParallel(net_pgd)\n    cudnn.benchmark = True\n\noptimizer_pgd = optim.SGD(net_pgd.parameters(), lr=lr, momentum=0.9, weight_decay=5e-4)\nscheduler_pgd = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer_pgd, T_max=200)\n# Train PGD model with progress\ntrain_losses_pgd = []\ntest_losses_pgd = []\nalpha = 3/255\nepsilon = 8/255\niter = 3\ntotal_start_time = time.time()\n\nfor epoch in range(epochs):\n    train_losses_pgd.append(train_pgd(epoch, net_pgd, alpha, epsilon, iter))\n    test_losses_pgd.append(test(epoch, net_pgd))\n    scheduler_pgd.step()\n\ntotal_time = time.time() - total_start_time\nprint(f'Total PGD training time: {total_time:.2f} seconds')\nprint('Accuracy of PGD-trained network: %d %%' % (acc))\n\n\n# Evaluate PGD model against PGD attacks with progress\ndef test_pgd(net, net_pgd, alpha, eps, iter):\n    net.train()\n    net_pgd.eval()\n    correct = 0\n    total = 0\n    start_time = time.time()\n    \n    with tqdm(testloader, unit=\"batch\") as tepoch:\n        tepoch.set_description(f\"PGD Test (iter={iter})\")\n        for batch_idx, (inputs, targets) in enumerate(tepoch):\n            inputs, targets = inputs.to(device), targets.to(device)\n            x_adv, _, _, _ = PGD(net, inputs, targets, alpha, eps, iter)\n\n            with torch.no_grad():\n                outputs = net_pgd(x_adv)\n                _, predicted = outputs.max(1)\n                total += targets.size(0)\n                correct += predicted.eq(targets).sum().item()\n                \n            # Update progress bar\n            tepoch.set_postfix(accuracy=100.*correct/total)\n    \n    test_time = time.time() - start_time\n    print(f\"PGD test (iter={iter}) time: {test_time:.2f} seconds\")\n    return 100 * correct / total\n\nprint(\"Evaluating against PGD attacks:\")\nfor iter in [3, 7, 12]:\n    accuracy = test_pgd(net, net_pgd, alpha, epsilon, iter)\n    print(f\"Iterations: {iter}, Accuracy: {accuracy:.2f}%\")\n\n# Save models with progress indication\nprint(\"Saving models...\")\nstart_time = time.time()\ntorch.save(net.state_dict(), 'natural_model.pth')\ntorch.save(net_adv.state_dict(), 'fgsm_model.pth')\ntorch.save(net_pgd.state_dict(), 'pgd_model.pth')\nprint(f\"Models saved in {time.time() - start_time:.2f} seconds\")","metadata":{"_uuid":"04e47202-77aa-4fa2-9fa7-579a3576f5b9","_cell_guid":"903ab9f1-13d2-4a64-8e4c-909ab71e2554","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-04-16T17:32:10.864184Z","iopub.execute_input":"2025-04-16T17:32:10.864485Z","iopub.status.idle":"2025-04-16T19:40:29.957763Z","shell.execute_reply.started":"2025-04-16T17:32:10.864461Z","shell.execute_reply":"2025-04-16T19:40:29.956981Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null}]}